{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantmoon Technologies - Intraday Backtester\n",
    "\n",
    "Backtester based on .zarr files for tick data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Importing General Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import queue\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload  \n",
    "from datetime import datetime\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "from fracdiff import StationaryFracDiff\n",
    "from math import floor\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "from dateutil import parser\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not useful during package construction\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Basic Extractor and Management Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Error and VWAP functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnAcceptedValueError(Exception):\n",
    "    \"\"\"\n",
    "    The following class defines a personalized ErrorMessage.\n",
    "    It'll be useful to compute any ErrorMessage\n",
    "    and returns it during a TRY-RAISE-EXCEPTION execution.\n",
    "    \n",
    "    It can be used many times given the input parameter\n",
    "    \"UnAcceptedValueError.data\" in the EXCEPTION execution statement.\n",
    "    \n",
    "    The content should be defined previously in the TRY statement\n",
    "    over the RAISE sentence.\n",
    "    \"\"\"\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "    def __str__(self):\n",
    "        return repr(self.data)\n",
    "    \n",
    "# time bar benchmark\n",
    "def compute_vwap(ds):\n",
    "    \"\"\"\n",
    "    The following code compute the VWAP\n",
    "    (Volume Weighted Average Price)\n",
    "    \n",
    "    The main formula is:\n",
    "    \n",
    "    VWAP = ∑(Price * Volume)/∑(Volume)\n",
    "    \n",
    "    It takes a pd.DataFrame of ticks \n",
    "    as a parameter with some specific\n",
    "    value types.\n",
    "    \n",
    "    Example 'df_ticks':\n",
    "        \n",
    "     \ttimestamp \tprice \tvolume\n",
    "    0 \t1586937600079 \t283.82 \t1000\n",
    "    1 \t1586937609055 \t284.41 \t216\n",
    "    \n",
    "    Format 'df_ticks':\n",
    "    \n",
    "    timestamp      int64\n",
    "    price        float64\n",
    "    volume         int64\n",
    "    dtype: object\n",
    "    \n",
    "    IMPORTANT\n",
    "    ---------\n",
    "    This functions was created to use\n",
    "    the output dataframe from the \n",
    "    \"get_tick_pricing()\" function.\n",
    "    \n",
    "    Another dataframe you'd like to use \n",
    "    have to fit the conditions described above.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sum(ds.value * ds.vol) / np.sum(ds.vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Data Time, Null Values and DataPreprocessing Management "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zarr_format_to_netcdf_format(file,\n",
    "                                 start_date,\n",
    "                                 end_date):  ##### ELIMINABLE--------------------------------------------------\n",
    "    \"\"\"\n",
    "    Transform the 'zarr' original xarray.Dataset format\n",
    "    into the 'netcdf' useful xarray.dataset structure.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        - file: directory/path of zarr files + 'stock.zarr' name.\n",
    "                Example: \"D:\\\\data_zarr\\\\AAPL.zarr\"\n",
    "        - date: useful date for extracting data\n",
    "        \n",
    "    Output:\n",
    "    -------\n",
    "    \n",
    "    xarray.Dataset structure similar to original netcdf.\n",
    "    Dimensions:  (date: #, n: ###, ts: ######)\n",
    "    \"\"\"\n",
    "    \n",
    "    #extracting data\n",
    "    data = xr.open_zarr(file)\n",
    "    \n",
    "    ######AGREGAR INITIALIZATION + STEP ###################### \n",
    "    \n",
    "    range_dates = [\n",
    "        str(np_date).partition('T')[0] for np_date \n",
    "        in data.date.sel(\n",
    "            date = slice(start_date,end_date)\n",
    "        ).values\n",
    "    ]\n",
    "        \n",
    "    list_df_=[]\n",
    "    for date in range_dates:\n",
    "        \n",
    "        #flattening prices | 'lev_cost'\n",
    "        \n",
    "        precios_flatten = data.lev_cost.sel(date=date).to_pandas(\n",
    "        ).transpose().rename_axis(None)\n",
    "        \n",
    "        precios_flatten = precios_flatten[precios_flatten!=0][:-1]\n",
    "\n",
    "        #flattening volume | 'lev_vol'\n",
    "        volumen_flatten = data.lev_vol.sel(date=date).to_pandas(\n",
    "        ).transpose().rename_axis(None)\n",
    "\n",
    "        volumen_flatten = volumen_flatten[volumen_flatten!=0][:-1] \n",
    "\n",
    "        #general dataframe: price + volume                              || HERE 1 \n",
    "        price_volume = pd.concat([volumen_flatten.to_frame(\"vol\"),\n",
    "                                  precios_flatten.to_frame(\"cost\")],\n",
    "                                 axis=1)\n",
    "        \n",
    "        #computing density levels for price-volume \n",
    "        density_levels = list(\n",
    "            filter(lambda num: num!=0,\n",
    "                   np.array(data.size.sel(date=date).values[:-1], \n",
    "                            dtype='int')\n",
    "                  )\n",
    "        )\n",
    "        \n",
    "        #computing timestamp ocurrency for level tick instance\n",
    "        timestamp_occurrency = list(map(int, \n",
    "                 filter(lambda num: num!=0, \n",
    "                        np.array(data.ubi.sel(date=date).values[:-1]))))\n",
    "        \n",
    "        reference = 0\n",
    "        \n",
    "        #iteration to define new format based on density levels\n",
    "        #                                                        || HERE 2\n",
    "        for idx, grouped_length in enumerate(density_levels):\n",
    "            df_ = price_volume[                      \n",
    "                reference:reference+grouped_length\n",
    "            ].assign( #asigna neva columna 'ts'\n",
    "                ts=timestamp_occurrency[idx]\n",
    "            ).assign( #asigna neva columna 'date'\n",
    "                date=date\n",
    "            )\n",
    "            #assigning a 'n' category of density level group\n",
    "            df_['n'] = np.arange(df_.shape[0]) + 1\n",
    "            \n",
    "            list_df_.append(df_)\n",
    "            #adding  the 'n' category value as iteration goes by\n",
    "            reference+=grouped_length\n",
    "            \n",
    "    #creates a new dataframe from each small 'n' groups df || #HERE 3 \n",
    "    temp_df_to_check = pd.concat(list_df_)\n",
    "    \n",
    "    #sys.exit()\n",
    "    \n",
    "    #                                                      || #HERE 4 \n",
    "    data_array_structure = temp_df_to_check.groupby(       \n",
    "        ['date', 'n', 'ts']\n",
    "    )[['vol','cost']].first()\n",
    "    \n",
    "    data_array_structure=data_array_structure.to_xarray().fillna(0)\n",
    "    #print (\"finished\")\n",
    "    # return final netcdf xarray.DataSet structure\n",
    "    \n",
    "    return data_array_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing_bt(file,\n",
    "                          initialization_step,\n",
    "                          step,\n",
    "                          start_date, \n",
    "                          end_date):\n",
    "    \"\"\"\n",
    "    Change timestamp \"ts\" netcdf attribute \n",
    "    to \"datetime\" object.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. openning cdf using xarray \n",
    "    netcdf_file = zarr_format_to_netcdf_format(file,\n",
    "                                               start_date,\n",
    "                                               end_date)\n",
    "\n",
    "    # 2. Redifine Milisecond Timestamp to second scale\n",
    "    netcdf_file['ts'] = netcdf_file.ts.values/(10**3)\n",
    "    \n",
    "    lst_ds_dates = []\n",
    "\n",
    "    # 3. iteration for sub-datasets per day\n",
    "    for date in netcdf_file.date.values:\n",
    "        \n",
    "        #4. temp dataset per day  \n",
    "        temp_data = netcdf_file.sel(date=date)\n",
    "\n",
    "        temp_data = temp_data.sel(\n",
    "            ts=slice(initialization_step,\n",
    "                     initialization_step+step)\n",
    "        )\n",
    "\n",
    "        \n",
    "        temp_data['ts'] = list(map(datetime.fromtimestamp,\n",
    "                                   temp_data.ts.values))\n",
    "        \n",
    "        \n",
    "        # 7. adding to a general datasets list\n",
    "        lst_ds_dates.append(temp_data)\n",
    "    \n",
    "    # 8. concat the subset of xarray datasets\n",
    "    new_general_ds = xr.concat(lst_ds_dates, \n",
    "                               dim='date')\n",
    "    \n",
    "    return new_general_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ewma(arr_in,window):\n",
    "    \"\"\"\n",
    "    The following code compute the EWMA\n",
    "    (Exponential Weighted Moving Average)\n",
    "    \n",
    "    Specifically, it computes an EWMA \n",
    "    for price variation -this means, volatility.\n",
    "    \n",
    "    The main formula is:\n",
    "\n",
    "    EWMA(t) = |Y1 if t=1\n",
    "              |alpha*Yt(1-alpha)· EWMA(t-1),t>1  \n",
    "    \n",
    "    Where:\n",
    "\n",
    "    * 'alpha' is the degree of weighting decrease, \n",
    "              a constant smoothing factor <0;1>. \n",
    "              Higher alpha discounts older observations faster.\n",
    "    \n",
    "    * 'Yt' is the value of data at time period 't'\n",
    "    * 'St' is the value of the EWMA at any time period 't'.\n",
    "    \n",
    "    Remember that: \n",
    "    \n",
    "    alpha =2/(window+1)\n",
    "    \n",
    "    * 'window' as a window_length for the EWMA \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr_in: array 1D of values (shape>1)\n",
    "    \n",
    "    window: int (>=1) \n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    ewma: array 1D (shape==arr_in) \n",
    "    \"\"\"\n",
    "    \n",
    "    #number of data points\n",
    "    n = arr_in.shape[0]\n",
    "    #an empty numpy to fill 'ewma' results\n",
    "    ewma = np.empty(n, dtype=np.float64)\n",
    "    #computation of \"alpha\" degree\n",
    "    alpha = 2 / float(window + 1)\n",
    "    #weight value | could be a float\n",
    "    w = 1\n",
    "    #first ewma: the first data point\n",
    "    #since it doesn't have previous values\n",
    "    ewma_old = arr_in[0]\n",
    "    #deine it in the first index\n",
    "    #in the ewma variable for returns\n",
    "    ewma[0] = ewma_old\n",
    "    #iterate over each data point\n",
    "    for i in range(1, n):\n",
    "        #increase weight value\n",
    "        #as long as the iterator increse\n",
    "        #the 'i' values\n",
    "        #based on the alpha degree\n",
    "        w += (1-alpha)**i\n",
    "        #compute a new \"ewma_old\"\n",
    "        ewma_old = ewma_old*(1-alpha) + arr_in[i]\n",
    "        #calculate the new ewma data point\n",
    "        ewma[i] = ewma_old / w\n",
    "    return ewma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Ts(bvs,\n",
    "               E_T_init,\n",
    "               abs_Ebv_init,\n",
    "               num_bars = 3):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute Imbalance-bar main \"ingridients\" \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    bvs: series-data signed flow | tick direction * volume\n",
    "    E_T_init: int | ticks to warm up\n",
    "    abs_Ebv_init: float| absolute mean value of E_T_init  \n",
    "    num_bars = int | desired number of bars you'll try to keep\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    - Ts: bar division index + bar direction\n",
    "    - abs_thetas: absolute theta values\n",
    "    - thresholds: threshold bounds\n",
    "    - i_s: division points \n",
    "    \n",
    "    ** abs_thetas: are the sum of the product\n",
    "                   between sign of the imbalance <1,-1>\n",
    "                   and the dollar volume of tick.\n",
    "                   Remember that sign is computed\n",
    "                   from the comparisson betwen \n",
    "                   tick in time 't' vs tick in 't-1'.\n",
    "                   \n",
    "                   In a brief:\n",
    "                   b: sign\n",
    "                   p: prices\n",
    "                   v: dollar volume\n",
    "                   t: time\n",
    "                   \n",
    "                   Δp[t] = p[t] - p[t-1]\n",
    "                   b[t] = |b[t-1] --> Δp[t]=0\n",
    "                          |sing(Δp[t]) otherwise\n",
    "                   v[t] = volume[t] * p[t]\n",
    "                   |theta[t]| = |∑(b[i]*v[i])|\n",
    "                   \n",
    "    ** thresholds: are the values for each bar.\n",
    "                   It's the same for all the values\n",
    "                   that belongs to the same bar.\n",
    "                   Example:\n",
    "                   Suppose 3 bars. A dataset of 1000 rows.\n",
    "                   \n",
    "                   Bar 1 goes from [0,449].\n",
    "                       All the values inside will have \n",
    "                       a value of \"1234\"\n",
    "                   So, inside 'Bar 1' you might see:\n",
    "                       [1234, 1234, 1234,...,1234]\n",
    "                       where shape of it is 450.\n",
    "                   The same for Bar 2, but with dif. values.\n",
    "        \n",
    "    ** i_s: are the points that divide the bars.\n",
    "            Suppose a dataet of 1000 row-prices.\n",
    "            'i_s' could be [560,720], meaning that\n",
    "            are three bars (if num_bars = 3): \n",
    "             a) one from idx 0 to idx 560,\n",
    "             b) another from idx 561 to 719\n",
    "             c) and the last one from 720 to 1000\n",
    "             \n",
    "        Information between this rows was stored.\n",
    "        It's why we call this \"information-driven\" bars.\n",
    "        \n",
    "        Important: \n",
    "        Not always 'numb_bars = 3' means output 3 bars.\n",
    "        It'll depend on the legnth of data,\n",
    "        and the info-data given in the df.\n",
    "        \n",
    "    ** Ts: computes a first bar divisor value\n",
    "           and the value inside that divisor\n",
    "           It returns the bars with positive value\n",
    "           \n",
    "           If you have a 'i_s' like:\n",
    "               [100,256]\n",
    "           Your 'Ts' might be: \n",
    "               [100,1.0]\n",
    "           Where all the values belong to\n",
    "           the bar that starts at idx 100\n",
    "           have 1.0 values.\n",
    "    \"\"\"\n",
    "    #performing Ts and i_s empty lists\n",
    "    Ts, i_s = [], []\n",
    "    #defining first general values\n",
    "    i_prev, E_T, abs_Ebv=0,E_T_init,abs_Ebv_init\n",
    "    \n",
    "    #keeping time series shapes\n",
    "    #remember: bvs = tick_dicrection * volume \n",
    "    n = bvs.shape[0]\n",
    "    #get values of bvs | bvs = tick_dicrection * volume\n",
    "    bvs_val = bvs.values.astype(np.float64)\n",
    "    #predefined abs_thetas and threshold values \n",
    "    #empty numpies\n",
    "    abs_thetas, thresholds = np.zeros(n),np.zeros(n)\n",
    "    #predefined first abs_thetas and cur_theta value\n",
    "    #cur_theta: current theta value\n",
    "    #remember: cur_theta = first value of 'bvs' values\n",
    "    #remember also: bvs = tick_dicrection * volume\n",
    "    abs_thetas[0],cur_theta = np.abs(bvs_val[0]),bvs_val[0]\n",
    "    \n",
    "    #iteration over total 'n' data points\n",
    "    for i in range(1, n):\n",
    "        #updating cur_theta\n",
    "        #adding the new bvs_val\n",
    "        cur_theta += bvs_val[i]\n",
    "        #redefining abs_theta for this new cur_theta\n",
    "        abs_theta = np.abs(cur_theta)\n",
    "        #updating new abs_thethas \n",
    "        #check that it respects the index 'i'\n",
    "        abs_thetas[i] = abs_theta\n",
    "        #updating a new threshold value\n",
    "        #compute the threshold as:\n",
    "        #E_T val (from E_T_init) x abs_Ebv val (from abs_Ebv_init) \n",
    "        threshold = E_T * abs_Ebv\n",
    "        #updating threshold information\n",
    "        #check that it reprects the index 'i'\n",
    "        thresholds[i] = threshold\n",
    "    \n",
    "        #computation of imbalance below!!!\n",
    "        \n",
    "        #if abs_theta(sing of price change * dollar_vol of tick)\n",
    "        #is gerater or equal to the resulted threshold\n",
    "        #define the cur_theta as '0'\n",
    "        if abs_theta >= threshold:\n",
    "            cur_theta=0\n",
    "            #updating the Ts. value\n",
    "            Ts.append(np.float64(i - i_prev))\n",
    "            #append it to the \"i_s\" variable\n",
    "            #using only the index\n",
    "            #we are instered in divide the datapoints\n",
    "            #into bars so that's why we use the index\n",
    "            i_s.append(i)\n",
    "            #redefine a i_prev value as the 'i' index\n",
    "            #to take it back into the next iteration\n",
    "            i_prev = i\n",
    "            #redefine E_T value as EWMA\n",
    "                #Inputs:\n",
    "                #array-timeseries: recent computed TS\n",
    "                #int-window: length of Ts \n",
    "            E_T = _ewma(\n",
    "                np.array(Ts),\n",
    "                window=np.int64(len(Ts))\n",
    "            )[-1] #return only the last values\n",
    "                  #as long as we are interested only \n",
    "                  #to assign the same EWMA value\n",
    "                  #if it corresponds to the same bar \n",
    "                \n",
    "            #redefine abs_Ebv value as EWMA\n",
    "                #Inputs:\n",
    "                #Array-bvs_val until the 'i' index point\n",
    "                #This group of data until that index\n",
    "                #corresponds to the same bar\n",
    "                #Window=E_T_init array * num desired bars \n",
    "            abs_Ebv = np.abs(\n",
    "                _ewma(\n",
    "                    bvs_val[:i],\n",
    "                    window=np.int64(E_T_init * num_bars)\n",
    "                )[-1]) #return only the last value \n",
    "                       #as long as we are interested only \n",
    "                       #to assign the same EWMA value\n",
    "                       #if it corresponds to the same bar             \n",
    "    return Ts, abs_thetas, thresholds, i_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. Basic Bar Generation by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_imbalance_tick_construction(df_ticks,\n",
    "                                    type_structure=\"vwap\"):\n",
    "    if type_structure == 'vwap':\n",
    "        df_ticks = df_ticks.apply(\n",
    "            lambda x: x.assign(\n",
    "                vwap=np.sum(x.price*x.volume)/np.sum(x.volume))\n",
    "            ).reset_index(['grpId'], drop=True)\n",
    "        \n",
    "    elif type_structure == 'mean':\n",
    "        df_ticks['mean'] = df_ticks['price'].mean()\n",
    "        \n",
    "    else:\n",
    "        print(\"Not cognized 'type_structure' parameter\")\n",
    "        \n",
    "    return df_ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bars_cdf_bt(file,\n",
    "             bartype,\n",
    "             initialization_step,\n",
    "             step,\n",
    "             start_date, \n",
    "             end_date,\n",
    "             freq=15,\n",
    "             ticks_warm_up='auto',\n",
    "             window_fracdiff=1,\n",
    "             actv_dfwap=True):\n",
    "    \"\"\"\n",
    "    Information Source: https://bit.ly/3fqFpAY\n",
    "    Cap. 2 - Financial Data Structures (Bars)\n",
    "    \n",
    "    Compute the selected data-bar type.\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    - file: string with the direction location of NetCDFs:\n",
    "            \n",
    "    - bartype: str that could de:\n",
    "             - 'tick': for tick bars\n",
    "             - 'volume': for volume bars\n",
    "             - 'dollar': for dollar volume bars\n",
    "             - 'imbalance': for imbalance bars\n",
    "             - 'fracdiff': for fractional derivative\n",
    "             \n",
    "    - initialization_step: lenght of timestamp you'll take as input\n",
    "                           in order to group and take your data.\n",
    "                           Example: 600000 = 10 first market minutes.\n",
    "                           This value will be updated iteritivally\n",
    "                           based of the 'step' or heart-beat' value.\n",
    "                           \n",
    "    - step: lenght of timestamp you'll consider as 'heart-beats'\n",
    "             This value represents how often you will update\n",
    "             the original 'initialization_step'.\n",
    "             Example: if step ('heart-beat') = 300000, this means\n",
    "             you will update the information each 5 minutes. \n",
    "             Thus, your first \"initialization_step\" will be 'X',\n",
    "             then after the first iteration, this will be X + 300000.\n",
    "             \n",
    "    - freq (predefined): int that reflects the time-series grouping\n",
    "            for the bars. It'll affect the number of bars,\n",
    "            as long as the VWAP computed.\n",
    "            \n",
    "            Remember that this is necessary because,\n",
    "            as humans, we need a time series representation\n",
    "            of the resulted formed bars.\n",
    "            \n",
    "    - ticks_warm_up (auto/ predefined): int>1000 or 'str' that reflects\n",
    "                                        max numbers of ticks\n",
    "                                        that we will considerate \n",
    "                                        to compute during\n",
    "                                        the tick bar separation\n",
    "                                        check more in \"compute_Ts()\".\n",
    "                                        Util for imbalance bars.\n",
    "                                        'Auto' (recommended).\n",
    "                                  \n",
    "    - window_fracdiff (predefined): 0< int <1 that reflects\n",
    "                                    the order of derivation\n",
    "                                    to calculate the fractional diff\n",
    "                                    of a set of numbers; in this case,\n",
    "                                    of a numpy.ndarray of prices.\n",
    "                                    Util for fracdiff bars.\n",
    "                                  \n",
    "    - actv_dfwap (predefined): bool that if it's true, it returns\n",
    "                               some other outputs that differs\n",
    "                               depends on the selected bar type.\n",
    "                               \n",
    "    Returns:\n",
    "    --------\n",
    "    Selected new computed bars based on its type.\n",
    "    \n",
    "    IMPORTANT\n",
    "    ---------\n",
    "    i) The reason why we use a Volume Weighted Average Price (vwap)\n",
    "        insted of the original tick time series as data-input\n",
    "        is due to the factor that the original series is highly variable\n",
    "        and extremely microscope (based on the miliseconds scale).\n",
    "        Thus it does not allow to appreciate the prices series correctly.\n",
    "        Try \"data.prices.plot()\" in your original dataset to see why.\n",
    "    \n",
    "    ii) In 'result_dataframe' construction, we use a 'split' process\n",
    "        over 'time_prices' information from a xarray.DataArray\n",
    "        because a string 'T' separates the DATE(T)HOUR-MINUTE-SECOND \n",
    "        in a np.array of time. So, as long as it belongs to this numpy,\n",
    "        we have to split this two parts and set DATE.datetime() format\n",
    "        as index and HOUR-MINUTE-SECOND like our variable in a column.\n",
    "        \n",
    "    iii)The conditional 'actv_dfwap' works differently depends\n",
    "        on the selected bar. Here is a list of hwo it works based on this:\n",
    "        \n",
    "        - 'time' & 'fracdiff': if actv_dfwap=True, \n",
    "                               returns VWAP based on typebar.\n",
    "                               Otherwise, returns mean.price. \n",
    "                               based on typebar.\n",
    "                               It can be stored in both sizes.\n",
    "                      \n",
    "        - 'tick', 'volume'\n",
    "           & 'dollar':   if actv_dfwap=True, \n",
    "                         it returns VWAP based on type bar.\n",
    "                         Otherwise, it returns original xarray.Dataset. \n",
    "                         Thus, it can be stored only if actv_dfwap=True. \n",
    "    \"\"\"\n",
    "\n",
    "    _bartypes = [\"time\",\"tick\",\"volume\",\"dollar\",\"imbalance\",'fracdiff']\n",
    "    bartype=bartype.lower()\n",
    "    \n",
    "    # checking general inputs\n",
    "    try:\n",
    "        if bartype not in _bartypes:\n",
    "            raise UnAcceptedValueError(\"\\\n",
    "            Only 'tick','volume','dollar','imbalance' as 'bartype'\")\n",
    "        elif type(file) != str:\n",
    "            raise UnAcceptedValueError(\"\\\n",
    "            Only 'str' route direction as 'file' input\")\n",
    "        elif type(freq)!=int or freq<=0:\n",
    "            raise UnAcceptedValueError(\"Wrong 'freq' input.\\\n",
    "            Only 'freq'>0 and 'int' type\")\n",
    "        elif type(actv_dfwap)!=bool:\n",
    "            raise UnAcceptedValueError(\"Only 'bool' type for 'df_vwap'\")\n",
    "        elif (type(window_fracdiff)!=int or \n",
    "              window_fracdiff<0 or \n",
    "              window_fracdiff>1):\n",
    "            raise UnAcceptedValueError(\"\\\n",
    "            Only positive 'int' type for 'window_fracdiff' arg.\")\n",
    "        else:\n",
    "            pass\n",
    "    except UnAcceptedValueError as mistake:\n",
    "        return \"Input Error Format: {}\".format(mistake.data)\n",
    "    \n",
    "    # STEP O: Extracting data\n",
    "    data=data_preprocessing_bt(file,\n",
    "                               initialization_step,\n",
    "                               step,\n",
    "                               start_date,\n",
    "                               end_date)\n",
    "     \n",
    "    ##################################################################\n",
    "    # STEP 1: General Data XArray Management#\n",
    "    \n",
    "    # 1.1. NaN cleaning\n",
    "    new_data=data.where(data!=0.).mean(\n",
    "        dim=\"date\",\n",
    "        skipna=True\n",
    "    )\n",
    "    \n",
    "    # 1.2. Flatting cleanned \n",
    "    new_data_value_flatt  = new_data.cost.stack(\n",
    "        ts_new = (\"ts\",\"n\")\n",
    "    )     \n",
    "    new_data_vol_flatt  = new_data.vol.stack(\n",
    "        ts_new = (\"ts\",\"n\")\n",
    "    )\n",
    "    \n",
    "    new_data_value_drop = new_data_value_flatt.dropna(\n",
    "        dim = \"ts_new\"\n",
    "    )\n",
    "    new_data_vol_drop = new_data_vol_flatt.dropna(\n",
    "        dim = \"ts_new\"\n",
    "    )\n",
    "    \n",
    "    # 1.3. grouping ticks by some 'freq'\n",
    "    resampling='{}Min'.format(freq)\n",
    "    netcdf_mean = data.where(data!=0.).mean(\n",
    "        dim=\"n\",\n",
    "        skipna=True).mean(dim = \"date\")\n",
    "    \n",
    "    # 1.4. renaming the variable 'cost' by 'value'(price)\n",
    "    netcdf_mean=netcdf_mean.rename({'cost':'value'})\n",
    "    \n",
    "    # 1.5. resample data by some 'freq'\n",
    "    group_data = netcdf_mean.resample(ts=resampling)\n",
    "    \n",
    "    # 1.6. get the resample dots\n",
    "    num_time_bars = len(group_data) \n",
    "    \n",
    "    ###############################################################\n",
    "    # STEP 2: General Bars Computation\n",
    "    \n",
    "    # Computation 2.1. - Time Bars | VWAP or Mean bar\n",
    "    if bartype=='time':\n",
    "        if actv_dfwap==False:\n",
    "            # 1.1. create mean price for each sample of some 'freq'\n",
    "            data_pricetime=group_data.mean()\n",
    "        else:\n",
    "            # 1.2. create vwap value for each sample of some 'freq'\n",
    "            data_pricetime=group_data.apply(compute_vwap)\n",
    "        \n",
    "        # 2. construction of final DataFrame\n",
    "        result_dataframe=pd.DataFrame(\n",
    "            {'time':[str(np_date).partition('T')[2] for np_date \n",
    "                     in data_pricetime.ts.values],\n",
    "             'price_fd':data_pricetime.values},\n",
    "            index=[str(np_date).partition('T')[0] for np_date \n",
    "                   in data_pricetime.ts.values]\n",
    "        ).iloc[::,::-1]\n",
    "        result_dataframe.index.name = \"date\"\n",
    "        return result_dataframe        \n",
    "    \n",
    "    # Computation 2.2. - Tick Bars\n",
    "    elif bartype=='tick':\n",
    "        \n",
    "            # 1. & 2. Modifying the original time series data\n",
    "            #   and get total of ticks and define num ticks per bar\n",
    "        total_ticks = new_data_value_drop.shape[-1]\n",
    "        num_ticks_per_bar = total_ticks/num_time_bars \n",
    "        num_ticks_per_bar = round(num_ticks_per_bar, -2)\n",
    "        \n",
    "            # 3. Setting a new axis given by the num ticks per bar\n",
    "        n_coo_ = []\n",
    "        for i in range(int(new_data_value_drop.shape[0]/\n",
    "                           num_ticks_per_bar)):\n",
    "            n_coo_ += [i]*int(num_ticks_per_bar) \n",
    "            \n",
    "            # 4. Setting the new coordinates in order as a list\n",
    "        n_coo_=n_coo_+[i+1]*(new_data_value_drop.shape[0]-len(n_coo_))  \n",
    "        \n",
    "            # 5. Align previous original information \n",
    "            #    using new grouped index 'n_coo_'\n",
    "            #    structure: xarray.DataArray\n",
    "        \n",
    "            # 5.1. data price value using 'n_coo_' index\n",
    "        new_data_value_util = new_data_value_drop.assign_coords(\n",
    "            ts_new = np.array(n_coo_)\n",
    "        )\n",
    "            # 5.2. data volume value using 'n_coo_' index\n",
    "        new_data_vol_util = new_data_vol_drop.assign_coords(\n",
    "            ts_new = np.array(n_coo_)\n",
    "        )\n",
    "            # 5.3. data time value using 'n_coo_' index\n",
    "        new_data_time_util = new_data_vol_drop.ts.assign_coords(\n",
    "            ts_new=np.array(n_coo_)\n",
    "        )\n",
    "            # 6. MAIN xarray.Dataset - Putting all together: \n",
    "            #    general base XarrayDataset tick/values\n",
    "            #    It includes previous information (5.1 - 5.3)\n",
    "        new_data_util = xr.Dataset(\n",
    "            {\"value\": new_data_value_util,\n",
    "             \"vol\": new_data_vol_util,\n",
    "             \"time\": new_data_time_util}\n",
    "        )\n",
    "        \n",
    "            # Conditional OUTPUT\n",
    "        if actv_dfwap==False:\n",
    "            # returns the original xarray.Dataset \n",
    "            # not for storage; just for print\n",
    "            # output format: xarray.Dataset\n",
    "            return new_data_util\n",
    "        else:\n",
    "            # returns the vwap computed from new/vol/bar\n",
    "            # output format: pd.DataFrame\n",
    "            \n",
    "            # 'Groupdata' using new/vol/bar coord type 'ts_new=n_coo_' \n",
    "            group_data=new_data_util.groupby(\"ts_new\")\n",
    "\n",
    "            # Results\n",
    "            #---------------------------------------------------------#\n",
    "            # RESULT 7.1: 'price' VWAP from new/dol/bar(dataArray)\n",
    "            price_vwap_tick_bar = group_data.apply(compute_vwap)\n",
    "\n",
    "            # RESULT 7.2: 'time' price VWAP from new/dol/bar(dataArray)\n",
    "            dtime_vwap_tick_bar = group_data.first(\"time\").time\n",
    "            \n",
    "            result_dataframe=pd.DataFrame(\n",
    "                {'time':[str(np_date).partition('T')[2] for np_date \n",
    "                          in dtime_vwap_tick_bar.values],\n",
    "                 'price':price_vwap_tick_bar.values},\n",
    "                index=[str(np_date).partition('T')[0] for np_date \n",
    "                          in dtime_vwap_tick_bar.values]\n",
    "            ).iloc[::,::-1]\n",
    "            \n",
    "            result_dataframe.index.name = \"date\"\n",
    "            \n",
    "            return result_dataframe\n",
    "    \n",
    "    # Computation 2.3. - Volume Bars\n",
    "    elif bartype=='volume':\n",
    "        \n",
    "            # 1. Compute the volume cumsum among ticks\n",
    "            #    in order to find the threshold limit of vol/bar        \n",
    "        data_cm_vol = new_data_vol_drop.values.cumsum()\n",
    "    \n",
    "            # 2. Get result of volume cumsum value among ticks\n",
    "            #    and define the threshold of vol/bar\n",
    "        total_vol = data_cm_vol[-1] \n",
    "        vol_per_bar = total_vol / num_time_bars\n",
    "        \n",
    "            # 3. round to the nearest hundred the volume per bar\n",
    "            #    in order to get a uniform series among different assets        \n",
    "        vol_per_bar = round(vol_per_bar, -2)\n",
    "\n",
    "            # 4. calculating new index using volume/bar threshold\n",
    "        n_coo_ = data_cm_vol//vol_per_bar\n",
    "        \n",
    "            # 5. Align previous original information \n",
    "            #    using new grouped index 'n_coo_'\n",
    "            #    structure: xarray.DataArray\n",
    "        \n",
    "            # 5.1. data volume cumulative sum value using 'n_coo_' index\n",
    "        new_data_cmvol_util=new_data_vol_drop.cumsum().assign_coords(\n",
    "            ts_new=n_coo_\n",
    "        )       \n",
    "            # 5.2. data price value using 'n_coo_' index\n",
    "        new_data_value_util=new_data_value_drop.assign_coords(\n",
    "            ts_new= n_coo_\n",
    "        )\n",
    "            # 5.3. data volume using 'n_coo_' index\n",
    "        new_data_vol_util=new_data_vol_drop.assign_coords(\n",
    "            ts_new=n_coo_\n",
    "        )\n",
    "            # 5.4. data time value using 'n_coo_' index\n",
    "        new_data_time_util=new_data_vol_drop.ts.assign_coords(\n",
    "            ts_new=n_coo_\n",
    "        )\n",
    "            # 6. MAIN xarray.Dataset - Putting all together: \n",
    "            #    general base XarrayDataset cum/vol/values\n",
    "            #    It includes previous information (5.1 - 5.4)\n",
    "        new_data_util = xr.Dataset(\n",
    "            {\"cmvol\":new_data_cmvol_util,\n",
    "             \"value\":new_data_value_util,\n",
    "             \"vol\":new_data_vol_util,\n",
    "             \"time\":new_data_time_util}\n",
    "        )\n",
    "        \n",
    "            # 7. Conditional OUTPUT\n",
    "        if actv_dfwap==False:\n",
    "            # returns the original xarray.Dataset \n",
    "            # not for storage; just for print\n",
    "            # output format: xarray.Dataset\n",
    "            return new_data_util\n",
    "        else:\n",
    "            # returns the vwap computed from new/vol/bar\n",
    "            # output format: pd.DataFrame\n",
    "            \n",
    "            # COMP1:groupdata using new/vol/bar coord type 'ts_new=n_coo_' \n",
    "            group_data=new_data_util.groupby(\"ts_new\")\n",
    "\n",
    "            # Results\n",
    "            #---------------------------------------------------------#\n",
    "            # RESULT 7.1: 'price' VWAP from new/vol/bar(dataArray)\n",
    "            price_vwap_vol_bar = group_data.apply(compute_vwap)\n",
    "\n",
    "            # RESULT 7.2: 'time' price VWAP from new/vol/bar(dataArray)\n",
    "            dtime_vwap_vol_bar = group_data.first(\"time\").time\n",
    "            \n",
    "            result_dataframe=pd.DataFrame(\n",
    "                {'time':[str(np_date).partition('T')[2] for np_date \n",
    "                          in dtime_vwap_vol_bar.values],\n",
    "                 'price':price_vwap_vol_bar.values},\n",
    "                index=[str(np_date).partition('T')[0] for np_date \n",
    "                          in dtime_vwap_vol_bar.values]\n",
    "            ).iloc[::,::-1]\n",
    "            result_dataframe.index.name = \"date\"\n",
    "            return result_dataframe\n",
    "        \n",
    "    #Computation 2.4. - Dollar Bars\n",
    "    elif bartype=='dollar':\n",
    "            # Price volatility is the rationale behind dollar bars\n",
    "            # we do the same process as the \"Volume Bars\"\n",
    "            # however, we will use \"dollar volume\" values\n",
    "            \n",
    "            # 1. Computing dollar value using directly xarray.DataArray\n",
    "        new_data_dollar_value =(new_data_value_drop*\n",
    "                                new_data_vol_drop)\n",
    "            \n",
    "            # 2. Compute the dollar volume value cumsum among ticks\n",
    "            #    in order to find the threshold limit of dollar per bar\n",
    "        data_cm_dol = new_data_dollar_value.values.cumsum()   \n",
    "        total_dol = data_cm_dol[-1] #final cumsum dollar data  \n",
    "        dol_per_bar = total_dol / num_time_bars\n",
    "\n",
    "            # 3. round to the nearest hundred the num_dollar_volume per bar\n",
    "            #    in order to get a uniform series among different assets\n",
    "        dol_per_bar = round(dol_per_bar, -2)\n",
    "        \n",
    "            # 4. calculating new index using dollar amount per bar\n",
    "        n_coo_ = data_cm_dol//dol_per_bar\n",
    "\n",
    "            # 5. Align previous original information \n",
    "            #    using new grouped index 'n_coo_'\n",
    "            #    structure: xarray.DataArray\n",
    "        \n",
    "            # 5.1. data dollar cumulative sum value using 'n_coo_' index\n",
    "        new_data_dol_util = new_data_dollar_value.cumsum().assign_coords(\n",
    "            ts_new= n_coo_\n",
    "        )\n",
    "            # 5.2. data price value using 'n_coo_' index\n",
    "        new_data_value_util = new_data_value_drop.assign_coords(\n",
    "            ts_new= n_coo_\n",
    "        )\n",
    "            # 5.3. data vol value using 'n_coo_' index\n",
    "        new_data_vol_util = new_data_vol_drop.assign_coords(\n",
    "            ts_new= n_coo_\n",
    "        )\n",
    "            # 5.4. data time value using 'n_coo_' index\n",
    "        new_data_time_util = new_data_dollar_value.ts.assign_coords(\n",
    "            ts_new=n_coo_\n",
    "        )\n",
    "        \n",
    "            # 6. MAIN xarray.Dataset - Putting all together: \n",
    "            #    general base XarrayDataset cum/dol/values\n",
    "            #    It includes previous information (5.1 - 5.4)\n",
    "        new_data_util = xr.Dataset(\n",
    "            {\"cmdol\":new_data_dol_util,\n",
    "             \"value\":new_data_value_util,\n",
    "             \"vol\":new_data_vol_util,\n",
    "             \"time\":new_data_time_util}\n",
    "        )\n",
    "        \n",
    "            # 7. Conditional OUTPUT:\n",
    "        if actv_dfwap==False:\n",
    "            # returns the original xarray.Dataset \n",
    "            # not for storage; just for print\n",
    "            # output format: xarray.Dataset\n",
    "            return new_data_util\n",
    "        else:\n",
    "            # returns the vwap computed from new/dol/bar\n",
    "            # output format: pd.DataFrame\n",
    "            \n",
    "            # COMP1:groupdata using new/dol/bar coord type 'ts_new=n_coo_' \n",
    "            group_data=new_data_util.groupby(\"ts_new\")\n",
    "\n",
    "            # Results\n",
    "            #---------------------------------------------------------#\n",
    "            # RESULT 7.1: 'price' VWAP from new/dol/bar(dataArray)\n",
    "            price_vwap_dol_bar = group_data.apply(compute_vwap)\n",
    "            \n",
    "            # RESULT 7.2: 'time' price VWAP from new/dol/bar(dataArray)\n",
    "            dtime_vwap_dol_bar = group_data.first(\"time\").time\n",
    "            \n",
    "            # Construct the final dataframe\n",
    "            result_dataframe=pd.DataFrame(\n",
    "                {'time':[str(np_date).partition('T')[2] for np_date \n",
    "                          in dtime_vwap_dol_bar.values],\n",
    "                 'price': price_vwap_dol_bar.values},\n",
    "                index= [str(np_date).partition('T')[0] for np_date \n",
    "                          in dtime_vwap_dol_bar.values]\n",
    "            ).iloc[::,::-1]\n",
    "            result_dataframe.index.name = \"date\"\n",
    "            return result_dataframe\n",
    "    \n",
    "    # Computation 2.5. - Fractional Derivative Bars    \n",
    "    elif bartype=='fracdiff':\n",
    "        # 1. construct the VWAP or series.mean\n",
    "        if actv_dfwap == False:\n",
    "            data_pricetime=group_data.mean()\n",
    "        else:\n",
    "            data_pricetime=group_data.apply(compute_vwap)\n",
    "        # 2. get numpy price values from 'VWAP' xarray.DataArray\n",
    "        data = data_pricetime.values\n",
    "\n",
    "        # 3. calculating the stationary version of price series\n",
    "        #    use a windows given as a parameter or default=1\n",
    "        fracdiff_ = StationaryFracDiff(window=window_fracdiff)\n",
    "        \n",
    "        try:\n",
    "            fracdiff_results = fracdiff_.fit_transform(data)\n",
    "        except ValueError:\n",
    "            print(\"Lack of samples to estimate the fracdiff for {}\".format(\n",
    "            (file.split(\"//\",1)[1])\n",
    "            )\n",
    "                 )\n",
    "            raise\n",
    "        \n",
    "        # 4. Drop the 'nan' values. Number of nan's=length of window\n",
    "        #    First 'n' datapoints should be 'nan' if window = n \n",
    "        fracdiff_results=fracdiff_results[~np.isnan(fracdiff_results)]\n",
    "        \n",
    "        # 5. Setting the time numpy values series on a variable \n",
    "        time_info = data_pricetime.ts.values[1:]\n",
    "        \n",
    "        # 6. constructing the result dataframe with time & price-values\n",
    "        result_dataframe=pd.DataFrame(\n",
    "            {'time':[str(np_date).partition('T')[2] for np_date \n",
    "                     in time_info],\n",
    "             'price_fd':fracdiff_results},\n",
    "            index=[str(np_date).partition('T')[0] for np_date \n",
    "                   in time_info]\n",
    "        ).iloc[::,::-1]\n",
    "        result_dataframe.index.name = \"date\"\n",
    "        return result_dataframe\n",
    "    \n",
    "    elif bartype=='imbalance':\n",
    "        # 1. construct dataframe of general information\n",
    "        data_timeidx = pd.DataFrame(\n",
    "            {'price':new_data_value_drop.values,\n",
    "             'volume':new_data_vol_drop.values},\n",
    "            index=new_data_value_drop.ts)\n",
    "        \n",
    "        # 2. estimation of tick direction\n",
    "        data_timeidx['tickDirection']=data_timeidx.price.diff(\n",
    "        ).fillna(\n",
    "            1.0\n",
    "        ).apply(\n",
    "            lambda x: \n",
    "            1 if x>0 else(\n",
    "                0 if x==0.0 else -1\n",
    "            )\n",
    "        ).replace(\n",
    "            to_replace=0,\n",
    "            method='ffill'\n",
    "        )\n",
    "        \n",
    "        # 3. compute the signs into the main dataset\n",
    "        data_signed_flow = data_timeidx.assign(\n",
    "            bv = data_timeidx.tickDirection * data_timeidx.volume\n",
    "        )\n",
    "        \n",
    "        # 4. get the mean absolute value of this datasigns\n",
    "        abs_Ebv_init = np.abs(data_signed_flow['bv'].mean())\n",
    "        \n",
    "        # 5. assign predefine max. number ticks to warm up\n",
    "        if type(ticks_warm_up)==str:\n",
    "            if ticks_warm_up.lower() == 'auto':\n",
    "                E_T_init = int(round(data_timeidx.shape[0]*.25,-1))\n",
    "            else:\n",
    "                print(\"Not recognized 'ticks_warm_up' arg. specification\")\n",
    "        elif type(ticks_warm_up)==int or type(ticks_warm_up) ==float:\n",
    "            if ticks_warm_up > 0:\n",
    "                E_T_init = int(ticks_warm_up)\n",
    "            else:\n",
    "                print(\"Invalid 'ticks_warm_up' value: only greater than 0\")\n",
    "        else:\n",
    "            print(\"Wrong 'ticks_warm_up' argument value. Redefine.\")\n",
    "        \n",
    "        # 6. getting the ingredients of imbalance bars\n",
    "        #    see \"compute_TS?\" function to know more\n",
    "        Ts, abs_thetas, thresholds, i_s = compute_Ts(\n",
    "            data_signed_flow.bv,\n",
    "            E_T_init,\n",
    "            abs_Ebv_init\n",
    "        )\n",
    "        \n",
    "        # 7. redefine the number of datapoints and some data\n",
    "        n = data_signed_flow.shape[0]\n",
    "            #redefine the index iterators\n",
    "        i_iter = iter(i_s + [n])\n",
    "            #redefine the current index \n",
    "            #this will be useful to iterate over it\n",
    "        i_cur = i_iter.__next__()\n",
    "            #get the imbalance var values \n",
    "            #empty numpy with zeros\n",
    "            #we will fill this during the loop\n",
    "        grpId = np.zeros(n)\n",
    "        \n",
    "        # 8. Loop iteration for each datapoint among all the datapoints\n",
    "        for i in range(1, n):\n",
    "            #if index <= than current index\n",
    "            #update the current imbalance bar variable-values\n",
    "            #with it's the previous value, mostly zero (the same)\n",
    "            if i <= i_cur:\n",
    "                grpId[i] = grpId[i-1]\n",
    "            #otherwise,    \n",
    "            #update the current imbalance bar variable-values\n",
    "            #with it's current value, mostly one (a new one)\n",
    "            else:\n",
    "                grpId[i] = grpId[i-1] + 1\n",
    "                #regenerate the iteration\n",
    "                #in the next bar\n",
    "                i_cur = i_iter.__next__()\n",
    "            #this distinction between:\n",
    "            #'grpId[i-1]' and 'grpId[i-1]+1'\n",
    "            #it's useful to differentiate values\n",
    "            #from one bar to another bar\n",
    "            #thus, values in first bar got zero, \n",
    "            #in the second bar one something like 1, \n",
    "            #and in the third one get, say, 2, \n",
    "            #and so on until the number of bars end.\n",
    "        \n",
    "        # 9. define the final data dollarVol imbalance var \n",
    "        #    based on the previous described distinction\n",
    "        #    among the values for different bars\n",
    "        data_dollar_imb_grp = data_signed_flow.assign(\n",
    "            grpId = grpId\n",
    "        )\n",
    "        \n",
    "        # 10. fit the final dollarVol imbalance var\n",
    "        #     to a time-series representation that able to percieve\n",
    "        #     to humans the time series; this mean, a VWAP - Price\n",
    "        \n",
    "        if actv_dfwap == True:\n",
    "            general_dataframe = bar_imbalance_tick_construction(\n",
    "                data_dollar_imb_grp.groupby('grpId'),\n",
    "                type_structure=\"vwap\").vwap\n",
    "        else:\n",
    "            general_dataframe = bar_imbalance_tick_construction(\n",
    "                data_dollar_imb_grp,\n",
    "                type_structure=\"mean\").mean\n",
    "            \n",
    "        # 11. create the last dataframe\n",
    "        groups = general_dataframe.groupby(general_dataframe)        \n",
    "        result_dataframe=pd.DataFrame(\n",
    "                {'time':[str(groups.groups[key][-1]).partition('T')[2] \n",
    "                         for key in groups.groups.keys()],\n",
    "                 'price':[key for key in groups.groups.keys()]},\n",
    "                index = [str(groups.groups[key][-1]).partition('T')[0]\n",
    "                        for key in groups.groups.keys()]\n",
    "            ).iloc[::,::-1]\n",
    "            \n",
    "        result_dataframe.index.name = \"date\"\n",
    "        return result_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Event Classes \n",
    "\n",
    "- Class Event\n",
    "- Class MarketEvent\n",
    "- Class SignalEvent\n",
    "- Class OrderEvent\n",
    "- Class FillEvent\n",
    "\n",
    "The core idea behind a backtester is to work during an iterative/loop process. This should goes from the first empty Event (the first consecuence from the initial \"heart-beat\") until the FillEvent. Later, the process should be restarted again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event(object):\n",
    "    \"\"\"\n",
    "    Event is base class providing an interface for all subsequent \n",
    "    (inherited) events, that will trigger further events in the \n",
    "    trading infrastructure.   \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class MarketEvent(Event):\n",
    "    \"\"\"\n",
    "    Handles the event of receiving a new market update with \n",
    "    corresponding bars.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialises the MarketEvent.\n",
    "        \"\"\"\n",
    "        self.type = 'MARKET'\n",
    "        \n",
    "class SignalEvent(Event):\n",
    "    \"\"\"\n",
    "    Handles the event of sending a Signal from a Strategy object.\n",
    "    This is received by a Portfolio object and acted upon.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, symbol, datetime, signal_type,strength):\n",
    "        \"\"\"\n",
    "        Initialises the SignalEvent.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - symbol: the ticker symbol, e.g. 'GOOG'.\n",
    "        - datetime: the timestamp at which the signal was generated.\n",
    "        - signal_type: 'LONG' or 'SHORT'.\n",
    "        - strength: adjustment factor \"suggestion\" used to scale values.\n",
    "                    Useful for pairs strategies and portfolio construction.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.type = 'SIGNAL'\n",
    "        self.symbol = symbol\n",
    "        self.datetime = datetime\n",
    "        self.signal_type = signal_type\n",
    "        self.strength = strength\n",
    "        \n",
    "class OrderEvent(Event):\n",
    "    \"\"\"\n",
    "    Handles the event of sending an Order to an execution system.\n",
    "    The order contains a symbol (e.g. GOOG), a type (market or limit),\n",
    "    quantity and a direction.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol, order_type, quantity, direction):\n",
    "        \"\"\"\n",
    "        Initialises the order type, setting whether it is\n",
    "        a Market order ('MKT') or Limit order ('LMT'), has\n",
    "        a quantity (integral) and its direction ('BUY' or\n",
    "        'SELL').\n",
    "\n",
    "        Parameters:\n",
    "        ------------\n",
    "        - symbol: The instrument to trade.\n",
    "        - order_type: 'MKT' or 'LMT' for Market or Limit.\n",
    "        - quantity: Non-negative integer for quantity.\n",
    "        - direction: 'BUY' or 'SELL' for long or short.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.type = 'ORDER'\n",
    "        self.symbol = symbol\n",
    "        self.order_type = order_type\n",
    "        self.quantity = quantity\n",
    "        self.direction = direction\n",
    "\n",
    "    def print_order(self):\n",
    "        \"\"\"\n",
    "        Outputs the values within the Order.\n",
    "        \"\"\"\n",
    "        print(\"Order: Symbol={0},Type={1},Quantity={2},Direction={3}\".format(\n",
    "            self.symbol, self.order_type, self.quantity, self.direction\n",
    "        )\n",
    "             )\n",
    "            \n",
    "class FillEvent(Event):\n",
    "    \"\"\"\n",
    "    Encapsulates the notion of a Filled Order, as returned\n",
    "    from a brokerage. Stores the quantity of an instrument\n",
    "    actually filled and at what price. In addition, stores\n",
    "    the commission of the trade from the brokerage.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, timeindex, symbol, exchange, quantity, \n",
    "                 direction, fill_cost, commission=None):\n",
    "        \"\"\"\n",
    "        Initialises the FillEvent object. Sets the symbol, exchange,\n",
    "        quantity, direction, cost of fill and an optional \n",
    "        commission.\n",
    "\n",
    "        If commission is not provided, the Fill object will\n",
    "        calculate it based on the trade size and Interactive\n",
    "        Brokers fees.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - timeindex: The bar-resolution when the order was filled.\n",
    "        - symbol: The instrument which was filled.\n",
    "        - exchange: The exchange where the order was filled.\n",
    "        - quantity: The filled quantity.\n",
    "        - direction: The direction of fill ('BUY' or 'SELL')\n",
    "        - fill_cost: The holdings value in dollars.\n",
    "        - commission: An optional commission sent from IB.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.type = 'FILL'\n",
    "        self.timeindex = timeindex\n",
    "        self.symbol = symbol\n",
    "        self.exchange = exchange\n",
    "        self.quantity = quantity\n",
    "        self.direction = direction\n",
    "        self.fill_cost = fill_cost\n",
    "\n",
    "        # Calculate commission\n",
    "        if commission is None:\n",
    "            self.commission = self.calculate_ib_commission()\n",
    "        else:\n",
    "            self.commission = commission\n",
    "\n",
    "    def calculate_ib_commission(self):\n",
    "        \"\"\"\n",
    "        Calculates the fees of trading based on an Interactive\n",
    "        Brokers fee structure for API, in USD.\n",
    "\n",
    "        This does not include exchange or ECN fees for data.\n",
    "\n",
    "        Based on \"US API Directed Orders\":\n",
    "        www.interactivebrokers.com/en/index.php?f=commission&p=stocks2\n",
    "        \"\"\"\n",
    "        commission_fees = 1.3\n",
    "        if self.quantity <= 500:\n",
    "            commission_fees = max(1.3, 0.013 * self.quantity)\n",
    "        else: \n",
    "            commission_fees = max(1.3, 0.008 * self.quantity)\n",
    "        return commission_fees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Data Handler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trading_Calendar():\n",
    "    \"\"\"\n",
    "    Funcion que llama los dias calendario de operacion del Nyse\n",
    "        \n",
    "    Input: empty\n",
    "    Output: Lista de datetimes de los dias calendario. \n",
    "    EL rango de la ultima acutalizacion es desde 02-01-1990\n",
    "    hasta 28-04-2021\n",
    "        \n",
    "    \"\"\"\n",
    "    datesDataset = pd.read_csv(\"trading_calendar_NYSE.csv\",\n",
    "                               delimiter=\";\", \n",
    "                               header=None)\n",
    "        \n",
    "    return datesDataset.apply(lambda x: datetime.strptime(\n",
    "        x.values[0].split(\"T\")[0],\n",
    "        '%Y-%m-%d').date()).tolist()\n",
    "\n",
    "\n",
    "def extract_date_avaible_market(start_, #solo se borro el 'self' | añadir para el cálculo de range dates\n",
    "                                end_,\n",
    "                                trd_cal_= Trading_Calendar()):\n",
    "    \"\"\"\n",
    "    Funcion necesaria para ejecutar match dias descarga con NYSE calendar.\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "        - start_: start_date string(\"Y-M-D\")\n",
    "        - end_: end_date string(\"Y-M-D\")\n",
    "        - trd_cal_: trading_calendar() function\n",
    "    Outputs:\n",
    "    -------\n",
    "        - Lista de dates válidos para descarga. \n",
    "            \n",
    "    * Nota: si en caso no existe días válidos para descarga, arroja un msj.\n",
    "    \"\"\"\n",
    "    \n",
    "    startDate=datetime.strptime(start_,'%Y-%m-%d')\n",
    "    endDate=datetime.strptime(end_,'%Y-%m-%d')\n",
    "        \n",
    "    if startDate == endDate:\n",
    "        list_pre = [startDate.date()]\n",
    "        idx = []\n",
    "        date = min(trd_cal_, key=lambda x: abs(x - list_pre[0]))\n",
    "        if date == list_pre[0]:\n",
    "                idx= [trd_cal_.index(date)]\n",
    "                resulted_dates_range = trd_cal_[idx[0]]\n",
    "                return [result_date_.strftime('%Y-%m-%d') \n",
    "                        for result_date_ in [resulted_dates_range]]\n",
    "        else:\n",
    "                return [\"No Markets Days\"]\n",
    "    else:\n",
    "        list_pre = [startDate.date(),endDate.date()]\n",
    "        idx = []\n",
    "        for date_ in list_pre:\n",
    "            date = min(trd_cal_, key=lambda x: abs(x - date_))\n",
    "            idx.append(trd_cal_.index(date))\n",
    "        resulted_dates_range = trd_cal_[idx[0]:idx[1]+1] \n",
    "        return [result_date_.strftime('%Y-%m-%d') \n",
    "                for result_date_ in resulted_dates_range]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler(object): \n",
    "    \"\"\"\n",
    "    DataHandler is an abstract base class providing an interface for\n",
    "    all subsequent (inherited) data handlers (both live and historic).\n",
    "\n",
    "    The goal of a (derived) DataHandler object is to output a generated\n",
    "    set of bars for each symbol requested. \n",
    "\n",
    "    This will replicate how a live strategy would function as current\n",
    "    market data would be sent \"down the pipe\". Thus a historic and live\n",
    "    system will be treated equally by the rest of the backtesting suite.\n",
    "    \"\"\"\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_latest_bars(self, symbol, N=1):\n",
    "        \"\"\"\n",
    "        Returns the last N bars from the latest_symbol list,\n",
    "        or fewer if less bars are available.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Should implement get_latest_bars()\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_bars(self):\n",
    "        \"\"\"\n",
    "        Pushes the latest bar to the latest symbol structure\n",
    "        for all symbols in the symbol list.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Should implement update_bars()\")\n",
    "        \n",
    "\n",
    "class HistoricNCDataHandler(DataHandler):           \n",
    "    \"\"\"\n",
    "    HistoricNCDataHandler is designed to read NetCDF files for\n",
    "    each requested symbol from disk and provide an interface\n",
    "    to obtain the \"latest\" bar in a manner identical to a live\n",
    "    trading interface. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, events, \n",
    "                 nc_dir, symbol_list,\n",
    "                 bartype,step,\n",
    "                 init,last,\n",
    "                 start_date,end_date,\n",
    "                 need=\"backtest\"):\n",
    "        \"\"\"\n",
    "        Initialises the historic data handler by requesting\n",
    "        the location of the NC files and a list of symbols.\n",
    "        \n",
    "        IMPORTANT:\n",
    "        It will be assumed that all files are of the form\n",
    "        'symbol.nc', where 'symbol' is a string in the list.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        -  events : The Event Queue.\n",
    "        -  nc_dir : Absolute directory path where NC files are stored.\n",
    "        -  symbol_list: A list of symbol strings\n",
    "        \n",
    "        ################ from our version ############################\n",
    "        \n",
    "        -  need: requirement for the code-structure. \n",
    "                 Could be 'backtest' for backtesting.\n",
    "                 Could be 'live' for live-trading.\n",
    "        - bartype: type of bar in which the backtesting will work.\n",
    "        - step: heart-beat timestamp.\n",
    "        - init: first timestamp period for bar (computed in milisecond)\n",
    "        - last: last timestamp period for bar (computed in milisecond)\n",
    "        \n",
    "        Output:\n",
    "        --------\n",
    "        Updated Bar Dataset (pd.DataFrame)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.events = events\n",
    "        self.nc_dir = nc_dir\n",
    "        self.symbol_list = symbol_list\n",
    "    \n",
    "        self.symbol_data = {}\n",
    "        self.latest_symbol_data = {}\n",
    "        \n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        \n",
    "        \n",
    "        for symbol in self.symbol_list:\n",
    "            # IMPORTANT: This is a refresh process. \n",
    "            # This process erase the last bar information\n",
    "            # in order to update accordingly with new information\n",
    "            # based on each 'step' or  'heart-beat'.\n",
    "            self.latest_symbol_data[symbol] = [] \n",
    "\n",
    "        self.continue_backtest = True\n",
    "        \n",
    "        self.need=need\n",
    "        self.step=step\n",
    "        self.bartype=bartype\n",
    "        #self.heartbeats=range(init,last,step)                               ###HERE | ITERATION RANGE\n",
    "        \n",
    "        iterationListTpls = list(itertools.product(\n",
    "            extract_date_avaible_market(self.start_date,\n",
    "                                        self.end_date),\n",
    "            [init,last])\n",
    "                                )\n",
    "        \n",
    "        iterableCoordInfo = [\n",
    "            [dt_coord[0] + \" \" + dt_coord[1]\n",
    "             for dt_coord in [iterationListTpls[limit:limit+2]][0]] \n",
    "            for limit in range(0, len(iterationListTpls), 2)\n",
    "        ]\n",
    "        \n",
    "        for coordInfo in iterableCoordInfo:\n",
    "            #coordInfo[0] #date (range: start_date - end_date) + init\n",
    "            #coordInfo[1] #date (range: start_date - end_date) + last\n",
    "            \n",
    "            _initialization = datetime.timestamp(\n",
    "                parser.parse(coordInfo[0])\n",
    "            )\n",
    "            _finalization = datetime.timestamp(\n",
    "                parser.parse(coordInfo[1])\n",
    "            )\n",
    "            \n",
    "            heartbeats = range(int(_initialization),\n",
    "                               int(_finalization),step)\n",
    "            \n",
    "        \n",
    "            if self.need == \"backtest\":\n",
    "                for heartbeat in heartbeats:\n",
    "                    self.open_convert_data_files(nc_dir,\n",
    "                                                 bartype, \n",
    "                                                 heartbeat,\n",
    "                                                 self.step,\n",
    "                                                 self.start_date,\n",
    "                                                 self.end_date)\n",
    "                    self.update_bars()\n",
    "            \n",
    "            elif self.need == \"live\":\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Something wrong during 'need' argue.\")\n",
    "                sys.exit()\n",
    "            \n",
    "        \n",
    "        #if self.need == \"backtest\":\n",
    "        #    for i in self.heartbeats:\n",
    "                # On each 'heart-beat' occurs both process:\n",
    "                # open and convert data files to update data constantly\n",
    "        #        self.open_convert_data_files(nc_dir,\n",
    "        #                                     bartype, \n",
    "        #                                     i,\n",
    "        #                                     self.step,\n",
    "        #                                     self.start_date,\n",
    "        #                                     self.end_date)\n",
    "        #        self.update_bars()\n",
    "\n",
    "        #elif self.need == \"live\":\n",
    "        #    pass\n",
    "        # Still in development\n",
    "            \n",
    "        \n",
    "    def open_convert_data_files(self,nc_dir,\n",
    "                                bartype,i,step,\n",
    "                                start_date,end_date):\n",
    "        \"\"\"\n",
    "        Opens the NC files from the path directory, converting\n",
    "        them into pandas DataFrames within a symbol dictionary.\n",
    "        \"\"\"\n",
    "        comb_index = None\n",
    "        \n",
    "        for s in self.symbol_list:\n",
    "            # Define the nc.file name structure\n",
    "            nc=self.nc_dir+\"/\"+s+\".zarr\"                \n",
    "            # Open the NetCDF file \n",
    "            df = get_bars_cdf_bt(nc,bartype,i,step,\n",
    "                                 start_date,end_date,\n",
    "                                 freq=5)\n",
    "            # Create a column with the daily value\n",
    "            df['date']=pd.to_datetime(df.index).strftime(\"%m-%d-%Y \")\n",
    "            # Add the time value (HR.Value)\n",
    "            df['date']=pd.to_datetime(df.date.add(df.time))\n",
    "            # Define the 'Date' TimeColumn as Index\n",
    "            df=df.set_index('date')\n",
    "            # Generates a dataset using DateTimeIndex and Prices values\n",
    "            df.drop(labels='time',axis=1,inplace=True)\n",
    "            # Result - DataFrame\n",
    "            self.symbol_data[s]=df\n",
    "            \n",
    "            \n",
    "            # Combine Indexes Values\n",
    "            # This process allows to update the index coordinates\n",
    "            # that reflects the timestamp base of our series\n",
    "            # as long as new 'steps' or 'heart-beats' occurs.\n",
    "            # So, new 'steps' or 'heart-beats' indicates\n",
    "            # new timeindexes-data to join to the previous sub-dataset\n",
    "            \n",
    "            \n",
    "            # If there is no previous Index Values\n",
    "            if comb_index is None:\n",
    "                # Get the First Index Value \n",
    "                comb_index = self.symbol_data[s].index\n",
    "                \n",
    "            # If there is a previous Index Value\n",
    "            else:\n",
    "                # Join the Previous Index Value with the new one\n",
    "                comb_index.union(self.symbol_data[s].index)\n",
    "    \n",
    "            # Set the latest symbol_data to None\n",
    "            # self.latest_symbol_data[s] = []\n",
    "    \n",
    "        # Reindex the dataframes\n",
    "        for s in self.symbol_list:\n",
    "            # Reset the original index of our result dataframe\n",
    "            self.symbol_data[s].reset_index(inplace=True)\n",
    "            \n",
    "            # Reassign the index in our empty-index result dataframe\n",
    "            # Here we use the 'comb_index' variable stored.\n",
    "            # If 'comb_index'=empty, basically the same index is assigned.\n",
    "            self.symbol_data[s].reindex(index=comb_index)\n",
    "            \n",
    "            # We define an 'iterrorws()' statement \n",
    "            # to return each row as in an iterative process\n",
    "            # to compute any future requirements.\n",
    "            self.symbol_data[s] = self.symbol_data[s].iterrows()\n",
    "\n",
    "            \n",
    "    def _start_web_socket():\n",
    "        \"\"\"\n",
    "        Function useful for live-trading only.\n",
    "        \"\"\"\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def get_latest_bars(self, symbol, N=1):\n",
    "            \"\"\"\n",
    "            Returns the last N bars from the latest_symbol list,\n",
    "            or N-k if less available.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                bars_list = self.latest_symbol_data[symbol]\n",
    "            except KeyError:\n",
    "                print (\"\\\n",
    "                Symbol not available in the historical data set\")\n",
    "                return (\"Process Stopped\")\n",
    "            else:\n",
    "                return bars_list[-N:]    \n",
    "    \n",
    "    def get_latest_bar_datetime(self, symbol):\n",
    "            \"\"\"\n",
    "            Returns a Python datetime object for the last bar.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                bars_list = self.latest_symbol_data[symbol]\n",
    "            except KeyError:\n",
    "                print(\"\\\n",
    "                Symbol not available in the historical data set.\")\n",
    "                raise\n",
    "            else:\n",
    "                return bars_list[-1][0]\n",
    "            \n",
    "    def get_latest_bar_value(self, symbol):\n",
    "            \"\"\"\n",
    "            Returns the last value from the pandas Bar series object.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                bars_list = self.latest_symbol_data[symbol]\n",
    "            except KeyError:\n",
    "                    print(\"\\\n",
    "                    Symbol not available in the historical data set.\")\n",
    "                    raise\n",
    "            else:\n",
    "                return bars_list[-1][1].values[1]\n",
    "            \n",
    "    def get_latest_bars_values(self, symbol, N=1):\n",
    "            \"\"\"\n",
    "            Returns the last N bar values from the\n",
    "            latest_symbol list, or N-k if less available.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                bars_list = self.get_latest_bars(symbol, N)\n",
    "            except KeyError:\n",
    "                print(\"\\\n",
    "                Symbol not available in the historical data set.\")\n",
    "                raise\n",
    "            else:\n",
    "                return np.array([bar[1] for bar in bars_list])\n",
    "            \n",
    "    # The original \"update_bars(self)\" method was changed. \n",
    "    # Here, we use a 'next()' statement to loop over the 'data' iterator.\n",
    "    # This avoid us to make another for-loop inside the 'try' statement.\n",
    "    # Using that reference, we'll fill the \"bar\" variable.\n",
    "    # If this information is None (which means no more data available),\n",
    "    # we \"StopIteration\" reassigning the \"continue_backtest\" as False.\n",
    "    # Remember that this \"self.continue_backtest\" was True originally.\n",
    "    # Otherwise, if there is some data in our \"bar\" variable,\n",
    "    # we will append that information as a \"last_symbol_data\"\n",
    "    # Wit this new information added, we set our event as MarketEvent().\n",
    "    # This ensures the code that we want to start the whole iteration\n",
    "    # that involves goes from MarketEvetn() data to FillEvent() data. \n",
    "    \n",
    "    def update_bars(self):\n",
    "        \"\"\"\n",
    "        Pushes the latest bar to the latest_symbol_data structure\n",
    "        for all symbols in the symbol list.\n",
    "        \"\"\"\n",
    "        for s in self.symbol_list:\n",
    "            try:\n",
    "                # Assign on each row the values of 'latest_symbol_data'\n",
    "                # as a constant updating process.\n",
    "                bar = [s,next(self.symbol_data[s])[1]]\n",
    "            except StopIteration:\n",
    "                self.continue_backtest = False\n",
    "            else:\n",
    "                if bar is not None:\n",
    "                    self.latest_symbol_data[s].append(bar)\n",
    "        #Assign the whole iterative process as MarketEvent()\n",
    "        self.events.put(MarketEvent())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Strategy Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Strategy Interface Class\n",
    "class Strategy(object):\n",
    "    \"\"\"\n",
    "    Strategy is an abstract base class providing an interface for\n",
    "    all subsequent (inherited) strategy handling objects.\n",
    "\n",
    "    The goal of a (derived) Strategy object is to generate Signal\n",
    "    objects for particular symbols based on the inputs of Bars \n",
    "    (OLHCVI) generated by a DataHandler object.\n",
    "\n",
    "    This is designed to work both with historic and live data as\n",
    "    the Strategy object is agnostic to the data source,\n",
    "    since it obtains the bar tuples from a queue object.\n",
    "    \"\"\"\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    @abstractmethod\n",
    "    def calculate_signals(self):\n",
    "        \"\"\"\n",
    "        Provides the mechanisms to calculate the list of signals.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Should implement calculate_signals()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personalized Strategy Computation\n",
    "#-----------------------------------------------------#\n",
    "# Here we should code more options to store a general trading signal. \n",
    "# It must work for any or mostly algorithmic computation we would make.\n",
    "\n",
    "# First, the class \"BuyAndHold\" should allows to define a global strategy\n",
    "# for any different investment approaches, no matter time-frameworks.\n",
    "# It implies not only long-buy-only approach, but long-short|long-only too.\n",
    "# This, offcourse, implies a \"selling\" part currently inexistance \n",
    "# and many other posibilities as a general interface.\n",
    "\n",
    "# The \"calculate initial bought\" class probably will be still the same.\n",
    "# The unique changes probably are about adding a \"sell\" statement.\n",
    "# This should represent the \"sell\" part of any \"buy\" transaction.\n",
    "# As you know, this should be defined as null or False at the beginning.\n",
    "\n",
    "# The class \"Calculate Signal\" is the ones will change mostly everytime.\n",
    "# This is because it contains the \"algoritmic\" logic of our strategy.\n",
    "# We have to define this everytime when try to compute an strategy.\n",
    "# This part will contain the ML or GIM (General Investment Model) to use.\n",
    "# Moreover, it should keep the \"signal\" boolean TRUE/FALSE by asset.\n",
    "# This boolean should be defined during the iteration every single time.\n",
    "\n",
    "class BuyAndHoldStrategy(Strategy):\n",
    "    \"\"\"\n",
    "    This is an extremely simple strategy that goes LONG all of the \n",
    "    symbols as soon as a bar is received. It will never exit a position.\n",
    "\n",
    "    It is primarily used as a testing mechanism for the Strategy class\n",
    "    as well as a benchmark upon which to compare other strategies.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bars, events):\n",
    "        \"\"\"\n",
    "        Initialises the buy and hold strategy.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - bars: The DataHandler object that provides bar information\n",
    "        - events: The Event Queue object.\n",
    "        \"\"\"\n",
    "        self.bars = bars\n",
    "        self.symbol_list = self.bars.symbol_list\n",
    "        self.events = events\n",
    "\n",
    "        # Once buy & hold signal is given, these are set to True\n",
    "        self.bought = self._calculate_initial_bought()\n",
    "        \n",
    "# strategy.py\n",
    "\n",
    "    def _calculate_initial_bought(self):\n",
    "        \"\"\"\n",
    "        Adds keys to the bought dictionary for all symbols\n",
    "        and sets them to False.\n",
    "        \"\"\"\n",
    "        bought = {}\n",
    "        for s in self.symbol_list:\n",
    "            bought[s] = False\n",
    "        return bought\n",
    "    \n",
    "# strategy.py\n",
    "\n",
    "    def calculate_signals(self, event):\n",
    "        \"\"\"\n",
    "        For \"Buy and Hold\" we generate a single signal per symbol\n",
    "        and then no additional signals. This means we are \n",
    "        constantly long the market from the date of strategy\n",
    "        initialisation.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        - Event: A MarketEvent object. \n",
    "        \"\"\"\n",
    "        strength = 1.0\n",
    "        if event.type == 'MARKET':\n",
    "            for s in self.symbol_list:\n",
    "                bars = self.bars.get_latest_bars(s, N=1) #definition of N bars\n",
    "                if bars is not None and bars != []:\n",
    "                    if self.bought[s] == False:\n",
    "                        # Inputs (to SignalEvent):\n",
    "                        # 1. Symbol (\"bars[0][1]\")\n",
    "                        # 2. Datetime (\"bars[0][1]\")\n",
    "                        # 3. Type (LONG, SHORT or EXIT as 'str')\n",
    "                        # 4. Strength (scale value predefined)\n",
    "                        signal = SignalEvent(bars[0][0], \n",
    "                                             bars[0][1], \n",
    "                                             'LONG', \n",
    "                                             strength)\n",
    "                        self.events.put(signal)\n",
    "                        self.bought[s] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sharpe_ratio(returns, periods=252):\n",
    "    \"\"\"\n",
    "    Create the Sharpe ratio for the strategy, based on a\n",
    "    benchmark of zero (i.e. no risk-free rate information).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - returns: A pandas Series representing period percentage returns.\n",
    "    - periods: Daily (252), Hourly (252*6.5), Minutely(252*6.5*60) etc.\n",
    "    \n",
    "    Output:\n",
    "    ------\n",
    "    - Anually Sharpe Ratio in Numpy.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt(periods) * (np.mean(returns)) / np.std(returns)\n",
    "\n",
    "def create_drawdowns(equity_curve):\n",
    "    \"\"\"\n",
    "    Calculate the largest peak-to-trough drawdown of the equity curve\n",
    "    as well as the duration of the drawdown. Requires that the\n",
    "    equity_returns is a pandas Series.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    - equity_curve: pandas series of returns.\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    - drawdown (pd.Series).\n",
    "    \"\"\"\n",
    "    # 1) filling NaN values from portfolio returns data\n",
    "    #    reduce to cero all positive values with 'clip'\n",
    "    data = equity_curve.dropna().clip(upper=0)\n",
    "\n",
    "    \n",
    "    # 2) get the max. values accumulated \n",
    "    running_max = np.maximum.accumulate(data.values)\n",
    "\n",
    "    \n",
    "    running_max[running_max < 1] = 1\n",
    "\n",
    "    \n",
    "    # 3) calculate drawdown \n",
    "    drawdown = (data.values)/running_max - 1\n",
    "\n",
    "    return  pd.Series(data,\n",
    "                      index=data.index).rename(\"drawdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - Portfolio Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio(object):\n",
    "    \"\"\"\n",
    "    The Portfolio class handles the positions and market\n",
    "    value of all instruments at a resolution of a \"bar\",\n",
    "    i.e. secondly, minutely, 5-min, 30-min, 60 min or EOD.\n",
    "    \"\"\"\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_signal(self, event):\n",
    "        \"\"\"\n",
    "        Acts on a SignalEvent to generate new orders \n",
    "        based on the portfolio logic.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Should implement update_signal()\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_fill(self, event):\n",
    "        \"\"\"\n",
    "        Updates the portfolio current positions and holdings \n",
    "        from a FillEvent.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Should implement update_fill()\")\n",
    "\n",
    "\n",
    "class NaivePortfolio(Portfolio):\n",
    "    \"\"\"\n",
    "    The NaivePortfolio object is designed to send orders to\n",
    "    a brokerage object with a constant quantity size blindly,\n",
    "    i.e. without any risk management or position sizing. It is\n",
    "    used to test simpler strategies such as BuyAndHoldStrategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 bars, \n",
    "                 events, \n",
    "                 start_date, \n",
    "                 initial_capital=100000.0):\n",
    "        \"\"\"\n",
    "        Initialises the portfolio with bars and an event queue. \n",
    "        Also includes a starting datetime index and initial capital \n",
    "        (USD unless otherwise stated).\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - bars: The DataHandler object with current market data.\n",
    "        - events: The Event Queue object.\n",
    "        - start_date: The start date (bar) of the portfolio.\n",
    "        - initial_capital: The starting capital in USD.\n",
    "        \"\"\"\n",
    "        self.bars = bars\n",
    "        self.events = events\n",
    "        self.symbol_list = self.bars.symbol_list\n",
    "        self.start_date = start_date\n",
    "        self.initial_capital = initial_capital\n",
    "        \n",
    "        self.all_positions = self.construct_all_positions()\n",
    "        self.current_positions={symbol: 0.0 for symbol in self.symbol_list}\n",
    "\n",
    "        self.all_holdings = self.construct_all_holdings()\n",
    "        self.current_holdings = self.construct_current_holdings()\n",
    "\n",
    "    def construct_all_positions(self):\n",
    "        \"\"\"\n",
    "        Constructs the positions list using the start_date\n",
    "        to determine when the time index will begin.\n",
    "        \"\"\"\n",
    "        d = {symbol: 0.0 for symbol in self.symbol_list}\n",
    "        \n",
    "        d['datetime'] = self.start_date #datetime\n",
    "        return [d]\n",
    "\n",
    "    def construct_all_holdings(self):\n",
    "        \"\"\"\n",
    "        Constructs the holdings list using the start_date\n",
    "        to determine when the time index will begin.\n",
    "        \"\"\"\n",
    "        d = {symbol: 0.0 for symbol in self.symbol_list}\n",
    "        \n",
    "        d['datetime'] = self.start_date #datetime\n",
    "        d['cash'] = self.initial_capital\n",
    "        d['commission'] = 0.0\n",
    "        d['total'] = self.initial_capital\n",
    "        \n",
    "        return [d]\n",
    "\n",
    "    def construct_current_holdings(self):\n",
    "        \"\"\"\n",
    "        Constructs the dictionary which will hold the instantaneous\n",
    "        value of the portfolio across all symbols.\n",
    "        \"\"\"\n",
    "        d = {symbol: 0.0 for symbol in self.symbol_list}\n",
    "        \n",
    "        d['cash'] = self.initial_capital\n",
    "        d['commission'] = 0.0\n",
    "        d['total'] = self.initial_capital\n",
    "        return d\n",
    "\n",
    "    def update_timeindex(self, event):\n",
    "        \"\"\"\n",
    "        Adds a new record to the positions matrix for the current \n",
    "        market data bar. This reflects the PREVIOUS bar, i.e. all\n",
    "        current market data at this stage is known.\n",
    "\n",
    "        Makes use of a MarketEvent from the events queue.\n",
    "        \"\"\"\n",
    "        bars = {}\n",
    "        for sym in self.symbol_list:\n",
    "            bars[sym] = self.bars.get_latest_bars(sym, N=1)\n",
    "\n",
    "        # Update positions\n",
    "        dp = {symbol: 0.0 for symbol in self.symbol_list}\n",
    "\n",
    "        dp['datetime'] = bars[self.symbol_list[0]][0][1]\n",
    "\n",
    "        for s in self.symbol_list:\n",
    "            dp[s] = self.current_positions[s]\n",
    "\n",
    "        # Append the current positions\n",
    "        self.all_positions.append(dp)\n",
    "\n",
    "        # Update portfolio holdings\n",
    "        dh = {symbol: 0.0 for symbol in self.symbol_list}\n",
    "        \n",
    "        dh['datetime'] = bars[self.symbol_list[0]][0][1].date\n",
    "        dh['cash'] = self.current_holdings['cash']\n",
    "        dh['commission'] = self.current_holdings['commission']\n",
    "        dh['total'] = self.current_holdings['cash']\n",
    "\n",
    "        for s in self.symbol_list:\n",
    "            # Approximation to the real value\n",
    "            market_value = (\n",
    "                self.current_positions[s]*bars[s][0][1].values[1]\n",
    "            )\n",
    "            dh[s] = market_value\n",
    "            dh['total'] += market_value\n",
    "\n",
    "        # Append the current holdings\n",
    "        self.all_holdings.append(dh)\n",
    "        \n",
    "\n",
    "    def update_positions_from_fill(self, fill):\n",
    "        \"\"\"\n",
    "        Takes a FilltEvent object and updates the position matrix\n",
    "        to reflect the new position.\n",
    "        \n",
    "        This represents an updating for some positions.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - fill: the FillEvent object to update the positions with.\n",
    "        \"\"\"\n",
    "        # Check whether the fill order direction is a buy or sell\n",
    "        fill_dir = 0\n",
    "        if fill.direction == 'BUY':\n",
    "            fill_dir = 1\n",
    "        if fill.direction == 'SELL':\n",
    "            fill_dir = -1\n",
    "\n",
    "        # Update positions list with new quantities\n",
    "        self.current_positions[fill.symbol] += fill_dir*fill.quantity\n",
    "\n",
    "    def update_holdings_from_fill(self, fill): \n",
    "        \"\"\"\n",
    "        Takes a FillEvent object and updates the holdings matrix\n",
    "        to reflect the holdings value.\n",
    "        \n",
    "        This represents an updating of the entire portfolio.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - fill: the FillEvent object to update the holdings with.\n",
    "        \"\"\"\n",
    "        # Check whether the fill is a buy or sell\n",
    "        fill_dir = 0\n",
    "        if fill.direction == 'BUY':\n",
    "            fill_dir = 1\n",
    "        if fill.direction == 'SELL':\n",
    "            fill_dir = -1\n",
    "\n",
    "        # Update holdings list with new investment quantities\n",
    "        fill_cost = self.bars.get_latest_bars(fill.symbol)[0][1].values[1] \n",
    "        cost = fill_dir * fill_cost * fill.quantity\n",
    "        self.current_holdings[fill.symbol] += cost\n",
    "        self.current_holdings['commission'] += fill.commission\n",
    "        self.current_holdings['cash'] -= (cost + fill.commission)\n",
    "        self.current_holdings['total'] -= (cost + fill.commission)\n",
    "    \n",
    "    #summarize the update positions and holdings\n",
    "    def update_fill(self, event): \n",
    "        \"\"\"\n",
    "        Updates the portfolio current positions and holdings \n",
    "        from a FillEvent.\n",
    "        \"\"\"\n",
    "        if event.type == 'FILL':\n",
    "            self.update_positions_from_fill(event)\n",
    "            self.update_holdings_from_fill(event)\n",
    "\n",
    "    def generate_naive_order(self, signal):\n",
    "        \"\"\"\n",
    "        Simply transacts an OrderEvent object as a constant quantity\n",
    "        sizing of the signal object, without risk management or\n",
    "        position sizing considerations.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - signal: The SignalEvent signal information.\n",
    "        \"\"\"\n",
    "        order = None\n",
    "        \n",
    "        symbol = signal.symbol\n",
    "        direction = signal.signal_type\n",
    "        strength = signal.strength\n",
    "        \n",
    "        #market quantity  - should be dynamic\n",
    "        mkt_quantity = floor(100 * strength)\n",
    "        cur_quantity = self.current_positions[symbol]\n",
    "        order_type = 'MKT'\n",
    "\n",
    "        if direction == 'LONG' and cur_quantity == 0:\n",
    "            order = OrderEvent(\n",
    "                symbol, order_type, mkt_quantity, 'BUY'\n",
    "            )\n",
    "            \n",
    "        if direction == 'SHORT' and cur_quantity == 0:\n",
    "            order = OrderEvent(\n",
    "                symbol, order_type, mkt_quantity, 'SELL'\n",
    "            )   \n",
    "    \n",
    "        if direction == 'EXIT' and cur_quantity > 0:\n",
    "            order = OrderEvent(\n",
    "                symbol, order_type, abs(cur_quantity), 'SELL'\n",
    "            )\n",
    "            \n",
    "        if direction == 'EXIT' and cur_quantity < 0:\n",
    "            order = OrderEvent(\n",
    "                symbol, order_type, abs(cur_quantity), 'BUY'\n",
    "            ) \n",
    "        return order\n",
    "\n",
    "    def update_signal(self, event):\n",
    "        \"\"\"\n",
    "        Acts on a SignalEvent to generate new orders \n",
    "        based on the portfolio logic.\n",
    "        \"\"\"\n",
    "        if event.type == 'SIGNAL':\n",
    "            order_event = self.generate_naive_order(event)\n",
    "            self.events.put(order_event)\n",
    "            \n",
    "    def create_equity_curve_dataframe(self):\n",
    "        \"\"\"\n",
    "        Creates a pandas DataFrame from the all_holdings\n",
    "        list of dictionaries.\n",
    "        \"\"\"\n",
    "        curve = pd.DataFrame(self.all_holdings)\n",
    "\n",
    "        curve.set_index('datetime', inplace=True)\n",
    "        curve['returns'] = curve['total'].pct_change()\n",
    "        curve['equity_curve'] = (1.0+curve['returns']).cumprod()\n",
    "        self.equity_curve = curve\n",
    "\n",
    "\n",
    "    def output_summary_stats(self):\n",
    "        \"\"\"\n",
    "        Creates a list of summary statistics for the portfolio.\n",
    "        \n",
    "        The main computed variables are:\n",
    "        \n",
    "        - 'total_return': represents the total return of the portfolio. \n",
    "        - 'returns': represents the returns obtained during the backtest.\n",
    "        - 'pnl': represents the profit & losses obtained during the backtest.\n",
    "        \n",
    "        All of them are pd.DataFrame.\n",
    "        \n",
    "        Output:\n",
    "        \n",
    "        tuple: (total_return,returns,pnl) \n",
    "        \"\"\"\n",
    "        total_return = self.equity_curve[\"equity_curve\"]\n",
    "        returns = self.equity_curve[\"returns\"]\n",
    "        pnl = self.equity_curve[\"equity_curve\"]\n",
    "        \n",
    "        sharpe_ratio = create_sharpe_ratio(returns)\n",
    "        drawdown = create_drawdowns(returns)\n",
    "        \n",
    "        stats = pd.concat([total_return.iloc[1:], \n",
    "                           returns.iloc[1:], \n",
    "                           drawdown], \n",
    "                      axis=1)\n",
    "        return stats, sharpe_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Execution Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecutionHandler(object):\n",
    "    \"\"\"\n",
    "    The ExecutionHandler abstract class handles the interaction\n",
    "    between a set of order objects generated by a Portfolio and\n",
    "    the ultimate set of Fill objects that actually occur in the\n",
    "    market. \n",
    "\n",
    "    The handlers can be used to subclass simulated brokerages\n",
    "    or live brokerages, with identical interfaces. This allows\n",
    "    strategies to be backtested in a very similar manner to the\n",
    "    live trading engine.\n",
    "    \"\"\"\n",
    "\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    @abstractmethod\n",
    "    def execute_order(self, event):\n",
    "        \"\"\"\n",
    "        Takes an Order event and executes it, producing\n",
    "        a Fill event that gets placed onto the Events queue.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - event: contains an Event object with order information.\n",
    "        \n",
    "        Output:\n",
    "        -------\n",
    "        - Implement/NotImplement Error Statement\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Should implement execute_order()\")\n",
    "\n",
    "class SimulatedExecutionHandler(ExecutionHandler):\n",
    "    \"\"\"\n",
    "    The simulated execution handler simply converts all order\n",
    "    objects into their equivalent fill objects automatically\n",
    "    without latency, slippage or fill-ratio issues.\n",
    "\n",
    "    This allows a straightforward \"first go\" test of any strategy,\n",
    "    before implementation with a more sophisticated execution\n",
    "    handler.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, events):\n",
    "        \"\"\"\n",
    "        Initialises the handler, setting the event queues\n",
    "        up internally.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - events: The Queue of Event objects.\n",
    "        \"\"\"\n",
    "        self.events = events\n",
    "\n",
    "    def execute_order(self, event):\n",
    "        \"\"\"\n",
    "        Simply converts Order objects into Fill objects naively,\n",
    "        i.e. without any latency, slippage or fill ratio problems.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - event: contains an Event object with order information.\n",
    "        \"\"\"\n",
    "        if event.type == 'ORDER':\n",
    "            # The \"FillEvent\" use 'ARCA' as purely name reference.\n",
    "            fill_event = FillEvent(datetime.utcnow(),\n",
    "                                   event.symbol,\n",
    "                                   'ARCA', \n",
    "                                   event.quantity, \n",
    "                                   event.direction, \n",
    "                                   None)\n",
    "            \n",
    "            self.events.put(fill_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import LinearAxis, Range1d, Band, HoverTool\n",
    "from bokeh.models import Line, Span\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "import bokeh.plotting.figure as bk_figure\n",
    "from bokeh.io import curdoc, show\n",
    "from bokeh.layouts import row, widgetbox\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.widgets import Slider, TextInput\n",
    "from bokeh.io import output_notebook \n",
    "import numpy as np\n",
    "\n",
    "from bokeh.application import Application\n",
    "from bokeh.application.handlers import FunctionHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_final_diagram(stats_dataframe, initial_capital):\n",
    "    \"\"\"\n",
    "    Function that plots a summary about stats information.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    - stats_dataframe: pd.DataFrame that contains performances info.\n",
    "    - initial_capita: float/int with predefined initial capital value\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    - Interactive plot of performance.\n",
    "    \n",
    "    Note:\n",
    "    ----\n",
    "    'Bokeh' visualization package was used. \n",
    "    Please, check: https://docs.bokeh.org/en/latest/index.html\n",
    "    \"\"\"\n",
    "    \n",
    "    #define main variables from stats_dataframe\n",
    "    x = stats_dataframe.index.values\n",
    "    \n",
    "    y1 = stats_dataframe.equity_curve\n",
    "    y2 = stats_dataframe.returns * 100\n",
    "    y3 = stats_dataframe.drawdown * 100\n",
    "    \n",
    "    portfolio_value = y1 * initial_capital \n",
    "    \n",
    "    #return results in the notebook\n",
    "    output_notebook()\n",
    "    \n",
    "    #general source of information\n",
    "    source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=x,\n",
    "            y1=y1,\n",
    "            y2=y2,\n",
    "            y3=y3,\n",
    "            money=portfolio_value)\n",
    "    )\n",
    "    \n",
    "    #constructing plot 1: portfolio equity curve line plot \n",
    "    plot1 = figure(plot_height=300,\n",
    "                   plot_width=800,\n",
    "                   y_axis_label = 'Cumulative Returns',\n",
    "                   title='Portfolio Curve',\n",
    "                   x_axis_type='datetime',\n",
    "                   background_fill_color = None) \n",
    "    \n",
    "    plot_ = plot1.line('x', 'y1', \n",
    "                       source=source, \n",
    "                       legend= 'backtest',\n",
    "                       line_color= 'green', \n",
    "                       line_width=2, \n",
    "                       line_alpha=1)\n",
    "    \n",
    "    plot1.add_tools(HoverTool(renderers=[plot_], \n",
    "                              tooltips=[('Cash','$@money{0.000 a}')],\n",
    "                              mode='vline'))\n",
    "    \n",
    "    plot1.legend.location = \"bottom_left\"\n",
    "    \n",
    "    daylight_savings_start = Span(location=1,\n",
    "                              dimension='width', line_color='black', \n",
    "                              line_dash='dashed', line_width=1)\n",
    "    \n",
    "    plot1.add_layout(daylight_savings_start)\n",
    "    \n",
    "    plot1.title.text_font = 'arial' \n",
    "    plot1.axis.axis_label_text_font = 'arial'\n",
    "    plot1.axis.axis_label_text_font_style = None\n",
    "    plot1.axis.major_label_text_font_size = '9.5pt'\n",
    "    plot1.title.text_font_size = '10pt'\n",
    "    \n",
    "    plot1.xgrid.grid_line_color = '#E4E4E4' \n",
    "    plot1.xgrid.grid_line_alpha = 0.7\n",
    "    \n",
    "    plot1.ygrid.grid_line_color = '#E4E4E4' \n",
    "    plot1.ygrid.grid_line_alpha = 0.7\n",
    "\n",
    "    #constructing plot 2: returns by each heartbeat \n",
    "    plot2 = figure(plot_height=300, \n",
    "                   plot_width=800, \n",
    "                   x_range = plot1.x_range, \n",
    "                   y_axis_label = 'Returns (%)',\n",
    "                   title='Heartbeat Returns (%)',\n",
    "                   x_axis_type='datetime',\n",
    "                   background_fill_color = None) \n",
    "    \n",
    "    plot_2 = plot2.line('x','y2',\n",
    "                        source=source,\n",
    "                        line_width=0,\n",
    "                        line_alpha=0)\n",
    "    plot2.add_tools(HoverTool(renderers=[plot_2], \n",
    "                              tooltips=[('Returns','@y2{0.000 a}%')],\n",
    "                              mode='vline'))\n",
    "\n",
    "    plot2.vbar(x=stats_dataframe[stats_dataframe.returns>0].index.values,\n",
    "               top=y2[y2>0], width = 4.25, \n",
    "               line_dash = 'solid',line_alpha = 0.9,\n",
    "               line_width = 4.25, color='#29399F') \n",
    "    plot2.vbar(x=stats_dataframe[stats_dataframe.returns<0].index.values, \n",
    "               top=y2[y2<0],width = 4.25,\n",
    "               line_dash = 'solid',line_alpha = 0.9,\n",
    "               line_width = 4.25, color='#AC2E3B')\n",
    "    \n",
    "    plot2.xgrid.grid_line_color = None\n",
    "    \n",
    "    plot2.title.text_font = 'arial'\n",
    "    plot2.axis.axis_label_text_font = 'arial'\n",
    "    plot2.axis.axis_label_text_font_style = None\n",
    "    plot2.axis.major_label_text_font_size = '9.5pt'\n",
    "    plot2.title.text_font_size = '10pt'\n",
    "    \n",
    "    plot2.xgrid.grid_line_color = '#E4E4E4' \n",
    "    plot2.xgrid.grid_line_alpha = 0.7\n",
    "    \n",
    "    plot2.ygrid.grid_line_color = '#E4E4E4'\n",
    "    plot2.ygrid.grid_line_alpha = 0.7\n",
    "    \n",
    "    #constructing plot 3: drawdowns curve by each heartbeat \n",
    "    plot3 = figure(plot_height=300, \n",
    "                   plot_width=800, \n",
    "                   x_range = plot1.x_range, \n",
    "                   x_axis_label = 'Datetime',\n",
    "                   y_axis_label = 'Drawdowns (%)',\n",
    "                   title='Heartbeat Drawdowns (%)',\n",
    "                   x_axis_type='datetime', \n",
    "                   background_fill_color = None) \n",
    "    \n",
    "    plot3.line('x', 'y3',source=source,\n",
    "              line_color = '#990000', \n",
    "              line_width=3, \n",
    "              line_alpha=0.1)\n",
    "    \n",
    "    plot3.patch('x', 'y3',source=source, color='#D24457')\n",
    "    \n",
    "    plot3.title.text_font = 'arial'\n",
    "    plot3.axis.axis_label_text_font = 'arial'\n",
    "    plot3.axis.axis_label_text_font_style = None\n",
    "    plot3.axis.major_label_text_font_size = '9.5pt'\n",
    "    plot3.title.text_font_size = '10pt'\n",
    "    \n",
    "    plot3.xgrid.grid_line_color = '#E4E4E4' \n",
    "    plot3.xgrid.grid_line_alpha = 0.7\n",
    "    \n",
    "    plot3.ygrid.grid_line_color = '#E4E4E4' \n",
    "    plot3.ygrid.grid_line_alpha = 0.7\n",
    "    \n",
    "    plot3.add_tools(HoverTool(tooltips=[('Drawdown','@y3{0.000 a}%')],\n",
    "                              mode='vline'))\n",
    "    \n",
    "    #linked all the plots \n",
    "    general_chart = gridplot([[plot1],\n",
    "                              [plot2],\n",
    "                              [plot3]], \n",
    "                             toolbar_location='right', title=\"ra\")\n",
    "    \n",
    "    #show plots as result\n",
    "    show(general_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtest(object):\n",
    "    \"\"\"\n",
    "    Enscapsulates the settings and components for carrying out\n",
    "    an event-driven backtest.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 data_dir, \n",
    "                 symbol_list, \n",
    "                 bartype,\n",
    "                 step_heartbeat,\n",
    "                 initialization_step,\n",
    "                 finalization_step,\n",
    "                 requirement,\n",
    "                 start_date,\n",
    "                 end_date,\n",
    "                 initial_capital,\n",
    "                 data_handler, #HistoricNCDataHandler\n",
    "                 execution_handler,#SimulatedExecutionHandler\n",
    "                 portfolio, #NaivePortfolio\n",
    "                 strategy #BuyAndHoldStrategy\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialises the backtest iteration loop.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        - data_dir (str): the hard root to the data directory.\n",
    "        - symbol_list (list of str): the list of symbol strings.\n",
    "        - intial_capital (float): the starting capital for the portfolio.\n",
    "        - heartbeat (int/float): backtest \"heartbeat\" in seconds.\n",
    "        - start_date (datetime): the start datetime of the strategy.\n",
    "        - data_handler (Class): market data feed HandleProces.\n",
    "        - execution_handler (Class): orders/fills for trades HandlesProces.\n",
    "        - portfolio (Class): tracker of portfolio current/prior positions.\n",
    "        - strategy (Class): Generates signals based on market data.\n",
    "        \n",
    "        Output:\n",
    "        --------\n",
    "        \n",
    "        Depends on callable method.\n",
    "        \n",
    "        Normally:\n",
    "        \n",
    "        'smiulate_trading()'.\n",
    "        \n",
    "        Includes:\n",
    "        - run_backtest\n",
    "        - out_performance\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        self.events = queue.Queue()\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        self.symbol_list = symbol_list\n",
    "        self.bart_type = bartype\n",
    "        self.heartbeat = step_heartbeat \n",
    "        self.init = initialization_step\n",
    "        self.last = finalization_step\n",
    "        self.need = requirement\n",
    "        \n",
    "        self.start_date = start_date \n",
    "        self.end_date = end_date\n",
    "        \n",
    "        self.initial_capital = initial_capital\n",
    "\n",
    "        self.data_handler_cls = data_handler\n",
    "        self.execution_handler_cls = execution_handler\n",
    "        self.portfolio_cls = portfolio\n",
    "        self.strategy_cls = strategy\n",
    "\n",
    "        self.signals = 0\n",
    "        self.orders = 0\n",
    "        self.fills = 0\n",
    "        self.num_strats = 1\n",
    "\n",
    "        self._generate_trading_instances()\n",
    "\n",
    "\n",
    "    def _generate_trading_instances(self):\n",
    "        \"\"\"\n",
    "        Generates the trading instance objects from\n",
    "        their class types.\n",
    "        \"\"\"\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        \n",
    "        print(\"1. Creating DataHandler\")\n",
    "        \n",
    "        self.data_handler = self.data_handler_cls(\n",
    "            self.events,\n",
    "            self.data_dir,\n",
    "            self.symbol_list,\n",
    "            self.bart_type,\n",
    "            self.heartbeat,\n",
    "            self.init,\n",
    "            self.last,\n",
    "            self.start_date,\n",
    "            self.end_date,\n",
    "            self.need\n",
    "        )\n",
    "        \n",
    "        print(\"2. Computing Strategy\")\n",
    "        \n",
    "        self.strategy = self.strategy_cls(\n",
    "            self.data_handler, \n",
    "            self.events\n",
    "        )\n",
    "        \n",
    "        print(\"3. Constructing Portfolio\")\n",
    "        \n",
    "        self.portfolio = self.portfolio_cls(\n",
    "            self.data_handler, \n",
    "            self.events, \n",
    "            self.start_date, \n",
    "            self.initial_capital\n",
    "        )\n",
    "        \n",
    "        print(\"4. Executing Handler Process\")\n",
    "        \n",
    "        self.execution_handler = self.execution_handler_cls(\n",
    "            self.events\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def _run_backtest(self):\n",
    "        \"\"\"\n",
    "        Executes the backtest thru an iteration process.\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        while True:\n",
    "            i += 1\n",
    "            \n",
    "            # 1) Updating the market bars\n",
    "            if self.data_handler.continue_backtest == True:\n",
    "                self.data_handler.update_bars()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            # 2) Handle Events Category\n",
    "            #    This means in which step of iteration we are.\n",
    "            #    Check \"event\" possible types.\n",
    "            #    Types: \n",
    "            #          'None': StopIteration\n",
    "            #          'Market': beginning-part (datahandler part)\n",
    "            #          'SignalEvent': first-half (strategy part)\n",
    "            #          'OrderEvent': second-half (portfolio part)\n",
    "            #          'FillEvent': final-part (execution part)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    event = self.events.get(False)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "                else:\n",
    "                    if event is not None:\n",
    "                        if isinstance(event, MarketEvent):\n",
    "                            self.strategy.calculate_signals(event)\n",
    "                            self.portfolio.update_timeindex(event)\n",
    "\n",
    "                        elif isinstance(event, SignalEvent):\n",
    "                            self.signals += 1\n",
    "                            self.portfolio.update_signal(event)\n",
    "\n",
    "                        elif isinstance(event, OrderEvent):\n",
    "                            self.orders += 1\n",
    "                            self.execution_handler.execute_order(event)\n",
    "\n",
    "                        elif isinstance(event, FillEvent):\n",
    "                            self.fills += 1\n",
    "                            self.portfolio.update_fill(event)\n",
    "\n",
    "            #time.sleep(1) #self.heartbeat\n",
    "\n",
    "    def _output_performance(self):\n",
    "        \"\"\"\n",
    "        Outputs the strategy performance from the backtest.\n",
    "        \"\"\"\n",
    "        self.portfolio.create_equity_curve_dataframe()\n",
    "        \n",
    "        print(\"\\nCreating summary stats...\")\n",
    "        stats = self.portfolio.output_summary_stats()\n",
    "\n",
    "        print(\"Creating equity curve...\\n\")\n",
    "        #print(self.portfolio.equity_curve.tail(10))\n",
    "        \n",
    "        print(\"FINAL REPORT\")\n",
    "        print(\"-\"*45)\n",
    "        \n",
    "        print(\"Annualized Sharpe Ratio:{}\\n\".format(round(stats[1],4)))\n",
    "        print(\"Signals: %s\" % self.signals)\n",
    "        print(\"Orders: %s\" % self.orders)\n",
    "        print(\"Fills: %s\" % self.fills)\n",
    "        \n",
    "        \n",
    "        plot_final_diagram(stats[0], self.initial_capital)\n",
    "        \n",
    "    def simulate_trading(self):\n",
    "        \"\"\"\n",
    "        Simulates the backtest and outputs portfolio performance.\n",
    "        \"\"\"\n",
    "        self._run_backtest()\n",
    "        self._output_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_dir='D:\\\\data_zarr\\\\'\n",
    "symbol_list=['A']\n",
    "need=\"backtest\"\n",
    "bartype=\"volume\"\n",
    "\n",
    "\n",
    "init = '09:30:00'\n",
    "last = '16:00:00'\n",
    "\n",
    "step = 100000\n",
    "\n",
    "event=queue.Queue()\n",
    "\n",
    "start_date = \"2019-01-08\"\n",
    "end_date = \"2019-01-08\"\n",
    "initial_capital = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Creating DataHandler\n",
      "2. Computing Strategy\n",
      "3. Constructing Portfolio\n",
      "4. Executing Handler Process\n"
     ]
    }
   ],
   "source": [
    "backtest_req = Backtest(data_dir=nc_dir, \n",
    "         symbol_list=symbol_list, \n",
    "         bartype=bartype,\n",
    "         step_heartbeat=step,\n",
    "         initialization_step=init,\n",
    "         finalization_step=last,\n",
    "         requirement=need,\n",
    "         start_date=start_date,\n",
    "         end_date = end_date,\n",
    "         initial_capital=initial_capital,\n",
    "         data_handler=HistoricNCDataHandler, #HistoricNCDataHandler\n",
    "         execution_handler=SimulatedExecutionHandler,#SimulatedExecutionHandler\n",
    "         portfolio=NaivePortfolio, #NaivePortfolio\n",
    "         strategy=BuyAndHoldStrategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTINUAR DONDE ESTÁ \n",
    "\n",
    "PENDIENTE: \n",
    "- Reemplazar zarr files con el data_extract_backup (ts: timestamp y no int restado).\n",
    "- Cambiar la computación del datetime | Reemplazar la función 'ts_to_datetime' por un lambda datetime.fromtimestamp() para todos los 'ts\n",
    "- Cambiar el parámetro de entrada de Init y Step por horas string (preguntar a Heli por el 'latido)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating summary stats...\n",
      "Creating equity curve...\n",
      "\n",
      "FINAL REPORT\n",
      "---------------------------------------------\n",
      "Annualized Sharpe Ratio:-0.0031\n",
      "\n",
      "Signals: 1\n",
      "Orders: 1\n",
      "Fills: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1706d41f-da65-459d-beba-6822ae335083\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1706d41f-da65-459d-beba-6822ae335083\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1706d41f-da65-459d-beba-6822ae335083\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1706d41f-da65-459d-beba-6822ae335083' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1706d41f-da65-459d-beba-6822ae335083\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1706d41f-da65-459d-beba-6822ae335083\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1706d41f-da65-459d-beba-6822ae335083\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1706d41f-da65-459d-beba-6822ae335083' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1706d41f-da65-459d-beba-6822ae335083\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"3a50e5a4-990d-4033-aff2-0d2ae9d3c5e6\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"5621c795-c739-4257-86c6-702b53bc9656\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"887a8840-67aa-4048-81b7-7e978283503e\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":3,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y3\"}},\"id\":\"13b7a2d9-fe63-4ea4-ae22-c9e8f56f203c\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"464ab49c-c50c-4770-88b5-b9990bcc1060\",\"type\":\"SaveTool\"},{\"attributes\":{\"plot\":null,\"text\":\"Heartbeat Returns (%)\",\"text_font\":\"arial\",\"text_font_size\":{\"value\":\"10pt\"}},\"id\":\"90475ce0-8113-45f5-b94f-9c067e07e9b9\",\"type\":\"Title\"},{\"attributes\":{\"source\":{\"id\":\"7de786de-a75b-46ac-895c-4e01384535f1\",\"type\":\"ColumnDataSource\"}},\"id\":\"6a584da6-84d0-43a4-81c3-3f06327f11fd\",\"type\":\"CDSView\"},{\"attributes\":{\"children\":[{\"id\":\"f2e5768c-11db-43a5-bb6c-632e72c20580\",\"subtype\":\"Figure\",\"type\":\"Plot\"}]},\"id\":\"19d20742-a8ee-41be-a275-3e7e15454683\",\"type\":\"Row\"},{\"attributes\":{\"plot\":null,\"text\":\"Portfolio Curve\",\"text_font\":\"arial\",\"text_font_size\":{\"value\":\"10pt\"}},\"id\":\"98f36533-2719-4a81-b095-db4cba09b3ec\",\"type\":\"Title\"},{\"attributes\":{\"overlay\":{\"id\":\"d44e44b1-d994-4f67-9b85-5e7872148ff7\",\"type\":\"BoxAnnotation\"}},\"id\":\"f1a64f53-d053-4fe6-99bc-75af63d09704\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"label\":{\"value\":\"backtest\"},\"renderers\":[{\"id\":\"d9459542-6484-4985-8f72-e70437c4ff05\",\"type\":\"GlyphRenderer\"}]},\"id\":\"48d74371-d03f-425e-a7f6-f988399fbdae\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"7de786de-a75b-46ac-895c-4e01384535f1\",\"type\":\"ColumnDataSource\"}},\"id\":\"c0270b8f-8b08-493e-b8d8-be2134edecf8\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"30364db1-d3e3-461d-a368-7d4c85789bde\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"487b516a-67cf-45b3-89cd-1991e1147dd3\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"75b276d1-458a-4a5b-aee4-fb68078c9a7f\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"8d4c6367-a1a5-4411-86bf-925fa3e60bc8\",\"type\":\"CDSView\"}},\"id\":\"fe235ab0-e136-4435-9abe-99ab3e6d50a4\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"97119daa-9012-41a5-a2a5-16afde415412\",\"type\":\"ColumnDataSource\"}},\"id\":\"da4d86be-8c83-4e55-ac80-e3351dc23bb7\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"940c57b6-9cb8-437e-8ad7-98665ae4f5cd\",\"type\":\"PanTool\"},{\"attributes\":{\"line_dash\":[6],\"location\":1,\"plot\":{\"id\":\"f2e5768c-11db-43a5-bb6c-632e72c20580\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"717af604-5137-432e-98b9-0fe950cbe359\",\"type\":\"Span\"},{\"attributes\":{\"source\":{\"id\":\"30364db1-d3e3-461d-a368-7d4c85789bde\",\"type\":\"ColumnDataSource\"}},\"id\":\"8d4c6367-a1a5-4411-86bf-925fa3e60bc8\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"14444b2a-a4d2-40e0-b491-ac642c1136e1\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"7de786de-a75b-46ac-895c-4e01384535f1\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"61be5d8d-8bbf-4e45-8ba4-dddd60c7de03\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"9d3dc3f0-8306-4cb9-a993-3ae8080c69e9\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"d4479b5e-1208-4801-8fac-b336353def5b\",\"type\":\"CDSView\"}},\"id\":\"ef70dcde-0a44-454d-9952-654055f33bd3\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y1\"}},\"id\":\"5344c29f-72eb-4316-bb83-b0f5758d5606\",\"type\":\"Line\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"44ff7bbc-fdcd-4c7f-a4dd-03915264220b\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"plot\":null,\"text\":\"Heartbeat Drawdowns (%)\",\"text_font\":\"arial\",\"text_font_size\":{\"value\":\"10pt\"}},\"id\":\"f414707e-1b21-46d0-bd50-44e92b2e4046\",\"type\":\"Title\"},{\"attributes\":{\"data_source\":{\"id\":\"97119daa-9012-41a5-a2a5-16afde415412\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"bd0a8658-73dd-439b-b9d3-ae2545d26074\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"3058d640-f699-4177-b2e6-dbda76bbabfa\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"da4d86be-8c83-4e55-ac80-e3351dc23bb7\",\"type\":\"CDSView\"}},\"id\":\"61efa8d1-66c7-43e7-9b8e-d428d129b185\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"children\":[{\"id\":\"8501c36f-a941-497a-a849-1c9529a4d78e\",\"subtype\":\"Figure\",\"type\":\"Plot\"}]},\"id\":\"457c7593-3aa0-483b-a26b-cd8033a05c4b\",\"type\":\"Row\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"68268b75-9629-4f25-9802-916d00483f61\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"aac8b388-997a-4810-9572-5887f8ff58fa\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"90e25634-41f2-407c-b6ed-177d662cf6f8\",\"type\":\"LinearScale\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"d365e98c-a537-4ad0-9d07-acdd36b3381d\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"f2edf1da-9d45-45ff-a878-a51e23e48f80\",\"type\":\"DaysTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"21ed1daf-42c2-4d73-9be1-e6e572db4158\",\"type\":\"DataRange1d\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"02cc74a2-3455-4fb0-9709-e27aa1057258\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"7de786de-a75b-46ac-895c-4e01384535f1\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"b098857b-3bcd-4719-8a38-4412136e18e0\",\"type\":\"Patch\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"a386cf44-9e2a-4344-856e-40a436af168c\",\"type\":\"Patch\"},\"selection_glyph\":null,\"view\":{\"id\":\"85210663-fdbe-437e-b197-08f8a1467581\",\"type\":\"CDSView\"}},\"id\":\"9e856e1b-081f-4151-ad90-4ef5ab49bed9\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"0581c71f-2e65-40d2-a3e6-dd4afacd9dc8\",\"type\":\"ResetTool\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"991fc1d8-e6a3-4430-8d6e-043e91274832\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"a8af5e0b-a998-4ac4-b3d1-e688e4b6f253\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"a276e4bb-c206-4e6a-adb5-bc34e3ece458\",\"type\":\"Selection\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"de3b8681-5915-493c-b519-1c7662c51669\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"fill_color\":\"#D24457\",\"line_color\":\"#D24457\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y3\"}},\"id\":\"b098857b-3bcd-4719-8a38-4412136e18e0\",\"type\":\"Patch\"},{\"attributes\":{\"background_fill_color\":{\"value\":null},\"below\":[{\"id\":\"b8b1f63a-4ef1-48d3-83fe-b3c871d2885d\",\"type\":\"DatetimeAxis\"}],\"left\":[{\"id\":\"643e9c79-d1eb-47db-bc17-2fba2d3b7b18\",\"type\":\"LinearAxis\"}],\"plot_height\":300,\"plot_width\":800,\"renderers\":[{\"id\":\"b8b1f63a-4ef1-48d3-83fe-b3c871d2885d\",\"type\":\"DatetimeAxis\"},{\"id\":\"f465c9ae-c7a1-4db3-aee9-f0b8be702ecf\",\"type\":\"Grid\"},{\"id\":\"643e9c79-d1eb-47db-bc17-2fba2d3b7b18\",\"type\":\"LinearAxis\"},{\"id\":\"ab516b74-eebc-4506-a92c-2b7e9d73f5ea\",\"type\":\"Grid\"},{\"id\":\"9a5595ab-1d61-4189-81a9-3cb9a8e5846a\",\"type\":\"BoxAnnotation\"},{\"id\":\"ac696a48-71bd-4747-85ca-fabc63ffd881\",\"type\":\"Legend\"},{\"id\":\"d9459542-6484-4985-8f72-e70437c4ff05\",\"type\":\"GlyphRenderer\"},{\"id\":\"717af604-5137-432e-98b9-0fe950cbe359\",\"type\":\"Span\"}],\"title\":{\"id\":\"98f36533-2719-4a81-b095-db4cba09b3ec\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"f7caec38-8fae-40fb-a3d8-3da2c126784e\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"fe79392f-8f3d-499e-b862-afa5a4d8579c\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"90e25634-41f2-407c-b6ed-177d662cf6f8\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"21ed1daf-42c2-4d73-9be1-e6e572db4158\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"b00f73f7-7fee-4adf-b834-56adef5ac61e\",\"type\":\"LinearScale\"}},\"id\":\"f2e5768c-11db-43a5-bb6c-632e72c20580\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null,\"data\":{\"top\":{\"__ndarray__\":\"IAA7oHPvvr8Ar4UcDVmRv4CrysvKU5W/AAS/tEaupb9oKQEf6AfTvyAitFrn38S/AEg7TRXhgL/gR+kqw7uyv6AlSFcXTb2/kKXM8hOEyL8ABpfjPbZyv2A/Bf5L1ry/QPPpwxxyrL9gIxWSz+e9vwC4eBufC2i/wPgcaa+KuL8AlB+rAkR5v0BVAjBWEKO/QHYWhNIZo78QkKoNgPLLvwA6vHhZ146/gFb4mEkSpL+APtISUuqQvwCdVuw84om/IP3qn6tNs7+Ae4+0Y1+mvwBiS5L6zaC/APQAbGQui78AcoRnXPGMvwBKb00IL3e/AAbjRzFmeb8AkMFSAl9zvwBRpGy27I2/wAIKXFiAp7/AssS1mxavvwDewih2BHu/ABDFUjGFZ78AYJ4qD4l7vwAMs5S+AGW/AJgcobLNf7+AXb50z/aZvw==\",\"dtype\":\"float64\",\"shape\":[41]},\"x\":{\"__ndarray__\":\"AAACBs6CdkIAoFEyzoJ2QgAQgmbOgnZCAAClwM6CdkIA0BErz4J2QgCgG2HPgnZCAFCakM+CdkIAEK020IJ2QgDg1gvRgnZCANDGYdGCdkIAwA540oJ2QgBAhOHSgnZCAODPO9OCdkIAADeg04J2QgBwLB/UgnZCAGAoo9SCdkIAMJ/p1YJ2QgBwjWbXgnZCABDZD9iCdkIAUJI62IJ2QgBwxlDZgnZCANCsTNuCdkIAwKWk3IJ2QgBQAizdgnZCACDog92CdkIA4PL73oJ2QgBw8lbfgnZCAPDsqt+CdkIA8A4G4IJ2QgBA/OjggnZCADDBoOGCdkIAMNnD4YJ2QgDA4gjignZCANA8bOKCdkIAcNiE4oJ2QgCQ0cfignZCAEDK3OKCdkIAIGHo4oJ2QgDwwvXignZCAKB/BuOCdkIAUKQM44J2Qg==\",\"dtype\":\"float64\",\"shape\":[41]}},\"selected\":{\"id\":\"a8af5e0b-a998-4ac4-b3d1-e688e4b6f253\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"fccb5b3f-2cc8-4cd2-a5b0-a89c85f3bbe5\",\"type\":\"UnionRenderers\"}},\"id\":\"30364db1-d3e3-461d-a368-7d4c85789bde\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"23dbe697-739b-43d1-bf7a-7c1c8704a839\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"dimension\":1,\"grid_line_alpha\":{\"value\":0.7},\"grid_line_color\":{\"value\":\"#E4E4E4\"},\"plot\":{\"id\":\"8501c36f-a941-497a-a849-1c9529a4d78e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"14444b2a-a4d2-40e0-b491-ac642c1136e1\",\"type\":\"BasicTicker\"}},\"id\":\"75af7969-aa99-4ab1-bebd-1b2885f1f0b4\",\"type\":\"Grid\"},{\"attributes\":{\"tools\":[{\"id\":\"2764a2c7-6f26-4506-99a5-034e24f1c194\",\"type\":\"PanTool\"},{\"id\":\"c53520d0-9b73-4a89-a47a-08aa433d499b\",\"type\":\"WheelZoomTool\"},{\"id\":\"6752a365-96bf-4eb7-9057-7ad562032916\",\"type\":\"BoxZoomTool\"},{\"id\":\"536be4ad-a8f0-48fc-9ba8-5ce0950c48a0\",\"type\":\"SaveTool\"},{\"id\":\"0581c71f-2e65-40d2-a3e6-dd4afacd9dc8\",\"type\":\"ResetTool\"},{\"id\":\"dbfdc5d9-e82b-4855-99fa-320de5b25c70\",\"type\":\"HelpTool\"},{\"id\":\"d0db49b5-d329-4534-bbfd-1589743eb3e6\",\"type\":\"HoverTool\"},{\"id\":\"6db156a9-df85-4b93-a5be-2f08a6a2e8ec\",\"type\":\"PanTool\"},{\"id\":\"b26ecd07-c886-4ae6-9e31-bb8c52070a00\",\"type\":\"WheelZoomTool\"},{\"id\":\"b23ae5a1-2b88-4069-b402-c112ca95b910\",\"type\":\"BoxZoomTool\"},{\"id\":\"464ab49c-c50c-4770-88b5-b9990bcc1060\",\"type\":\"SaveTool\"},{\"id\":\"605139a5-88df-4fd7-8218-17f56b15b63f\",\"type\":\"ResetTool\"},{\"id\":\"ceba60db-b174-45a9-ba43-f07b3543333f\",\"type\":\"HelpTool\"},{\"id\":\"b68874eb-6fc9-47c6-abce-3ed7befdf925\",\"type\":\"HoverTool\"},{\"id\":\"940c57b6-9cb8-437e-8ad7-98665ae4f5cd\",\"type\":\"PanTool\"},{\"id\":\"e2e34abc-d439-41df-ab0e-0ef480cb9296\",\"type\":\"WheelZoomTool\"},{\"id\":\"f1a64f53-d053-4fe6-99bc-75af63d09704\",\"type\":\"BoxZoomTool\"},{\"id\":\"2de75654-4045-493e-b93f-99092838ecc0\",\"type\":\"SaveTool\"},{\"id\":\"ea1c3263-161e-4c44-8948-4a6d7fbf2271\",\"type\":\"ResetTool\"},{\"id\":\"9ad9c1e7-e155-49f3-8474-fc8c52750157\",\"type\":\"HelpTool\"},{\"id\":\"cd620d13-472a-4c73-921f-44886c84511a\",\"type\":\"HoverTool\"}]},\"id\":\"fd60f4ef-9bd3-4fd5-8031-74d0e406ea76\",\"type\":\"ProxyToolbar\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"73c33c80-67e5-4c7c-900c-41c7ae97c193\",\"type\":\"DaysTicker\"},{\"attributes\":{\"children\":[{\"id\":\"19d20742-a8ee-41be-a275-3e7e15454683\",\"type\":\"Row\"},{\"id\":\"d68e4e2b-f4ce-4315-93d5-fccc05e0d01c\",\"type\":\"Row\"},{\"id\":\"457c7593-3aa0-483b-a26b-cd8033a05c4b\",\"type\":\"Row\"}]},\"id\":\"c3ee3e62-b73e-4192-9e3d-2e60dbf49815\",\"type\":\"Column\"},{\"attributes\":{},\"id\":\"afa0f998-d9aa-4ea8-b62d-98ae01f70a67\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null,\"mode\":\"vline\",\"renderers\":\"auto\",\"tooltips\":[[\"Drawdown\",\"@y3{0.000 a}%\"]]},\"id\":\"cd620d13-472a-4c73-921f-44886c84511a\",\"type\":\"HoverTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"2764a2c7-6f26-4506-99a5-034e24f1c194\",\"type\":\"PanTool\"},{\"id\":\"c53520d0-9b73-4a89-a47a-08aa433d499b\",\"type\":\"WheelZoomTool\"},{\"id\":\"6752a365-96bf-4eb7-9057-7ad562032916\",\"type\":\"BoxZoomTool\"},{\"id\":\"536be4ad-a8f0-48fc-9ba8-5ce0950c48a0\",\"type\":\"SaveTool\"},{\"id\":\"0581c71f-2e65-40d2-a3e6-dd4afacd9dc8\",\"type\":\"ResetTool\"},{\"id\":\"dbfdc5d9-e82b-4855-99fa-320de5b25c70\",\"type\":\"HelpTool\"},{\"id\":\"d0db49b5-d329-4534-bbfd-1589743eb3e6\",\"type\":\"HoverTool\"}]},\"id\":\"f7caec38-8fae-40fb-a3d8-3da2c126784e\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null},\"id\":\"fe79392f-8f3d-499e-b862-afa5a4d8579c\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"9ad9c1e7-e155-49f3-8474-fc8c52750157\",\"type\":\"HelpTool\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"24c0b7cd-4ad8-4303-a3db-1ba73714a6e4\",\"type\":\"AdaptiveTicker\"},{\"id\":\"23dbe697-739b-43d1-bf7a-7c1c8704a839\",\"type\":\"AdaptiveTicker\"},{\"id\":\"79db95c7-9aa8-4562-824d-938ec206e7a2\",\"type\":\"AdaptiveTicker\"},{\"id\":\"c3c9ccc2-67ec-4462-9fe4-66d85699a86d\",\"type\":\"DaysTicker\"},{\"id\":\"73c33c80-67e5-4c7c-900c-41c7ae97c193\",\"type\":\"DaysTicker\"},{\"id\":\"68268b75-9629-4f25-9802-916d00483f61\",\"type\":\"DaysTicker\"},{\"id\":\"2978e819-6920-4670-8529-a753df2df06e\",\"type\":\"DaysTicker\"},{\"id\":\"3e165250-4213-4656-9865-4bdba32e2aed\",\"type\":\"MonthsTicker\"},{\"id\":\"de3b8681-5915-493c-b519-1c7662c51669\",\"type\":\"MonthsTicker\"},{\"id\":\"7dbf681d-837f-4fab-9a5c-71cdf400f975\",\"type\":\"MonthsTicker\"},{\"id\":\"57ee02ce-7692-4b73-bef4-2d812061ccee\",\"type\":\"MonthsTicker\"},{\"id\":\"e2543d03-5a57-4e90-88cf-47443be19e86\",\"type\":\"YearsTicker\"}]},\"id\":\"db8f48e0-7ad1-41b3-ad0d-bb221ab404f2\",\"type\":\"DatetimeTicker\"},{\"attributes\":{},\"id\":\"3917073a-328d-4cc1-bf72-d64f80a068ef\",\"type\":\"LinearScale\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"88ebac88-e17a-4308-86dd-80d94939c3d7\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"overlay\":{\"id\":\"b95a2747-4d25-4835-bad9-7a6d778f3147\",\"type\":\"BoxAnnotation\"}},\"id\":\"b23ae5a1-2b88-4069-b402-c112ca95b910\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"a1d7d312-a875-4c31-a396-449d9e3f535d\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"3e165250-4213-4656-9865-4bdba32e2aed\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"ea1c3263-161e-4c44-8948-4a6d7fbf2271\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"145fcae9-2652-42d6-9de8-d39e7890a6ee\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis_label\":\"Drawdowns (%)\",\"axis_label_text_font\":\"arial\",\"axis_label_text_font_style\":null,\"formatter\":{\"id\":\"145fcae9-2652-42d6-9de8-d39e7890a6ee\",\"type\":\"BasicTickFormatter\"},\"major_label_text_font_size\":{\"value\":\"9.5pt\"},\"plot\":{\"id\":\"8501c36f-a941-497a-a849-1c9529a4d78e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"14444b2a-a4d2-40e0-b491-ac642c1136e1\",\"type\":\"BasicTicker\"}},\"id\":\"ca15b728-725c-45dc-842b-f8ff15551666\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"536be4ad-a8f0-48fc-9ba8-5ce0950c48a0\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"0e3b4c67-a6dd-4272-8881-95fe2ee5649e\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"2978e819-6920-4670-8529-a753df2df06e\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"01d4448f-5a4f-4c8c-9ccf-83b6febbe13d\",\"type\":\"Selection\"},{\"attributes\":{\"toolbar\":{\"id\":\"fd60f4ef-9bd3-4fd5-8031-74d0e406ea76\",\"type\":\"ProxyToolbar\"}},\"id\":\"052778e9-35ca-4843-acdd-ef85872bc708\",\"type\":\"ToolbarBox\"},{\"attributes\":{},\"id\":\"b00f73f7-7fee-4adf-b834-56adef5ac61e\",\"type\":\"LinearScale\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"04fa28d1-2176-4492-bd24-d47bca468c40\",\"type\":\"DaysTicker\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"3b7c44f2-f0b5-4d35-b3de-2739ae5ab289\",\"type\":\"DaysTicker\"},{\"attributes\":{\"callback\":null,\"mode\":\"vline\",\"renderers\":[{\"id\":\"ef70dcde-0a44-454d-9952-654055f33bd3\",\"type\":\"GlyphRenderer\"}],\"tooltips\":[[\"Returns\",\"@y2{0.000 a}%\"]]},\"id\":\"b68874eb-6fc9-47c6-abce-3ed7befdf925\",\"type\":\"HoverTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"940c57b6-9cb8-437e-8ad7-98665ae4f5cd\",\"type\":\"PanTool\"},{\"id\":\"e2e34abc-d439-41df-ab0e-0ef480cb9296\",\"type\":\"WheelZoomTool\"},{\"id\":\"f1a64f53-d053-4fe6-99bc-75af63d09704\",\"type\":\"BoxZoomTool\"},{\"id\":\"2de75654-4045-493e-b93f-99092838ecc0\",\"type\":\"SaveTool\"},{\"id\":\"ea1c3263-161e-4c44-8948-4a6d7fbf2271\",\"type\":\"ResetTool\"},{\"id\":\"9ad9c1e7-e155-49f3-8474-fc8c52750157\",\"type\":\"HelpTool\"},{\"id\":\"cd620d13-472a-4c73-921f-44886c84511a\",\"type\":\"HoverTool\"}]},\"id\":\"746ae6b8-8654-4d79-8fb7-3fa26e283239\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"b26ecd07-c886-4ae6-9e31-bb8c52070a00\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"grid_line_alpha\":{\"value\":0.7},\"grid_line_color\":{\"value\":\"#E4E4E4\"},\"plot\":{\"id\":\"dd7a8270-8d27-488b-888a-0368fe1cefd9\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"45faab98-1289-4aef-985f-6bb9329c9b34\",\"type\":\"DatetimeTicker\"}},\"id\":\"db6367df-3294-4540-bd99-c6831bd4968e\",\"type\":\"Grid\"},{\"attributes\":{\"children\":[{\"id\":\"c3ee3e62-b73e-4192-9e3d-2e60dbf49815\",\"type\":\"Column\"},{\"id\":\"052778e9-35ca-4843-acdd-ef85872bc708\",\"type\":\"ToolbarBox\"}]},\"id\":\"47a37777-e138-4995-9abf-89e8b816c1f5\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"b03c1faf-7697-43fc-9321-493180e49753\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"57ee02ce-7692-4b73-bef4-2d812061ccee\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"8e780530-8f69-443c-951d-158d7e1b774f\",\"type\":\"LinearScale\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"24c0b7cd-4ad8-4303-a3db-1ba73714a6e4\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"c3c9ccc2-67ec-4462-9fe4-66d85699a86d\",\"type\":\"DaysTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"9a5595ab-1d61-4189-81a9-3cb9a8e5846a\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"69acbfb2-bf0f-49a6-a016-a15ae64c441d\",\"type\":\"DaysTicker\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"ab3531d4-82d3-4999-b724-5a80d99de1a6\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"background_fill_color\":{\"value\":null},\"below\":[{\"id\":\"da572bf5-c9b5-45aa-8492-f63260815349\",\"type\":\"DatetimeAxis\"}],\"left\":[{\"id\":\"ca15b728-725c-45dc-842b-f8ff15551666\",\"type\":\"LinearAxis\"}],\"plot_height\":300,\"plot_width\":800,\"renderers\":[{\"id\":\"da572bf5-c9b5-45aa-8492-f63260815349\",\"type\":\"DatetimeAxis\"},{\"id\":\"a88f4852-78d2-4122-a56c-ec9b9debae25\",\"type\":\"Grid\"},{\"id\":\"ca15b728-725c-45dc-842b-f8ff15551666\",\"type\":\"LinearAxis\"},{\"id\":\"75af7969-aa99-4ab1-bebd-1b2885f1f0b4\",\"type\":\"Grid\"},{\"id\":\"d44e44b1-d994-4f67-9b85-5e7872148ff7\",\"type\":\"BoxAnnotation\"},{\"id\":\"12f49b48-f620-4069-aa6d-3eb45a2eafbf\",\"type\":\"GlyphRenderer\"},{\"id\":\"9e856e1b-081f-4151-ad90-4ef5ab49bed9\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"f414707e-1b21-46d0-bd50-44e92b2e4046\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"746ae6b8-8654-4d79-8fb7-3fa26e283239\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"fe79392f-8f3d-499e-b862-afa5a4d8579c\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"22b9b048-b8dd-40bc-bad2-eed54a8e46d3\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"4ef4acf9-bbee-45ce-ae11-8080a7896737\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"3917073a-328d-4cc1-bf72-d64f80a068ef\",\"type\":\"LinearScale\"}},\"id\":\"8501c36f-a941-497a-a849-1c9529a4d78e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis_label_text_font\":\"arial\",\"axis_label_text_font_style\":null,\"formatter\":{\"id\":\"66e583e2-e6e5-4c40-b8b6-89462e19fc4e\",\"type\":\"DatetimeTickFormatter\"},\"major_label_text_font_size\":{\"value\":\"9.5pt\"},\"plot\":{\"id\":\"f2e5768c-11db-43a5-bb6c-632e72c20580\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"db8f48e0-7ad1-41b3-ad0d-bb221ab404f2\",\"type\":\"DatetimeTicker\"}},\"id\":\"b8b1f63a-4ef1-48d3-83fe-b3c871d2885d\",\"type\":\"DatetimeAxis\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"79db95c7-9aa8-4562-824d-938ec206e7a2\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"7de786de-a75b-46ac-895c-4e01384535f1\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"09e6016d-93fa-4a48-a9a2-fd2477ae06cf\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"13b7a2d9-fe63-4ea4-ae22-c9e8f56f203c\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"c0270b8f-8b08-493e-b8d8-be2134edecf8\",\"type\":\"CDSView\"}},\"id\":\"12f49b48-f620-4069-aa6d-3eb45a2eafbf\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_color\":{\"value\":\"#AC2E3B\"},\"line_alpha\":{\"value\":0.9},\"line_color\":{\"value\":\"#AC2E3B\"},\"line_width\":{\"value\":4.25},\"top\":{\"field\":\"top\"},\"width\":{\"value\":4.25},\"x\":{\"field\":\"x\"}},\"id\":\"487b516a-67cf-45b3-89cd-1991e1147dd3\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"2de75654-4045-493e-b93f-99092838ecc0\",\"type\":\"SaveTool\"},{\"attributes\":{\"axis_label\":\"Returns (%)\",\"axis_label_text_font\":\"arial\",\"axis_label_text_font_style\":null,\"formatter\":{\"id\":\"9bfb9edd-0c00-4929-8c6e-5a7de7207568\",\"type\":\"BasicTickFormatter\"},\"major_label_text_font_size\":{\"value\":\"9.5pt\"},\"plot\":{\"id\":\"dd7a8270-8d27-488b-888a-0368fe1cefd9\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"afa0f998-d9aa-4ea8-b62d-98ae01f70a67\",\"type\":\"BasicTicker\"}},\"id\":\"b64e5a90-4df6-467c-a4c1-635cedc5c283\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null},\"id\":\"df5c8ee3-ddc1-49df-b214-2fb828974a51\",\"type\":\"DataRange1d\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"8edfe27d-e391-4ac0-a8b4-a4257d8a1184\",\"type\":\"AdaptiveTicker\"},{\"id\":\"a1d7d312-a875-4c31-a396-449d9e3f535d\",\"type\":\"AdaptiveTicker\"},{\"id\":\"5d05a9d5-6ada-4e51-a707-88347195bea3\",\"type\":\"AdaptiveTicker\"},{\"id\":\"3b7c44f2-f0b5-4d35-b3de-2739ae5ab289\",\"type\":\"DaysTicker\"},{\"id\":\"04fa28d1-2176-4492-bd24-d47bca468c40\",\"type\":\"DaysTicker\"},{\"id\":\"991fc1d8-e6a3-4430-8d6e-043e91274832\",\"type\":\"DaysTicker\"},{\"id\":\"b4c31fcd-2c5e-40b3-8fb7-9057585cf5e0\",\"type\":\"DaysTicker\"},{\"id\":\"d365e98c-a537-4ad0-9d07-acdd36b3381d\",\"type\":\"MonthsTicker\"},{\"id\":\"44ff7bbc-fdcd-4c7f-a4dd-03915264220b\",\"type\":\"MonthsTicker\"},{\"id\":\"ae102af0-95eb-49eb-800a-a6c2d3ffb04b\",\"type\":\"MonthsTicker\"},{\"id\":\"2fea732b-dd74-442e-853b-54571dfa72a2\",\"type\":\"MonthsTicker\"},{\"id\":\"d4251c26-d979-45ef-9748-9f3c5c376208\",\"type\":\"YearsTicker\"}]},\"id\":\"45faab98-1289-4aef-985f-6bb9329c9b34\",\"type\":\"DatetimeTicker\"},{\"attributes\":{\"overlay\":{\"id\":\"9a5595ab-1d61-4189-81a9-3cb9a8e5846a\",\"type\":\"BoxAnnotation\"}},\"id\":\"6752a365-96bf-4eb7-9057-7ad562032916\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#990000\",\"line_width\":3,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y3\"}},\"id\":\"09e6016d-93fa-4a48-a9a2-fd2477ae06cf\",\"type\":\"Line\"},{\"attributes\":{\"grid_line_alpha\":{\"value\":0.7},\"grid_line_color\":{\"value\":\"#E4E4E4\"},\"plot\":{\"id\":\"f2e5768c-11db-43a5-bb6c-632e72c20580\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"db8f48e0-7ad1-41b3-ad0d-bb221ab404f2\",\"type\":\"DatetimeTicker\"}},\"id\":\"f465c9ae-c7a1-4db3-aee9-f0b8be702ecf\",\"type\":\"Grid\"},{\"attributes\":{\"grid_line_alpha\":{\"value\":0.7},\"grid_line_color\":{\"value\":\"#E4E4E4\"},\"plot\":{\"id\":\"8501c36f-a941-497a-a849-1c9529a4d78e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"08dd9bfd-02c8-4aff-aded-08210f7fed5f\",\"type\":\"DatetimeTicker\"}},\"id\":\"a88f4852-78d2-4122-a56c-ec9b9debae25\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"605139a5-88df-4fd7-8218-17f56b15b63f\",\"type\":\"ResetTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"value\":4.25},\"top\":{\"field\":\"top\"},\"width\":{\"value\":4.25},\"x\":{\"field\":\"x\"}},\"id\":\"75b276d1-458a-4a5b-aee4-fb68078c9a7f\",\"type\":\"VBar\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"ae102af0-95eb-49eb-800a-a6c2d3ffb04b\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"8edfe27d-e391-4ac0-a8b4-a4257d8a1184\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"callback\":null,\"data\":{\"money\":{\"__ndarray__\":\"AAAAAACIw0AAAAAAAIjDQHq0ajv1gcNAQQBcpRyBw0DC6vlrEoDDQEjdFUP1fcNAMnatuh5vw0DUbW2nAWfDQI7/3dqYZsNA94g7L71sw0DKj3yeGWnDQIyI8orva8NAiCyEtT5mw0BPo7Wqu1zDQPsiKWRfX8NA6eNa6wZmw0C1r4/XzGXDQLbSc9k0YMNAFZGMXXNdw0AViIHQqFfDQNE5VpuDV8NAg0lLa8RSw0DV6n1iTFbDQHz6xiMUXMNAkATM4MVbw0DPXvKwvGPDQF038ivyZcNA5DaB0hhkw0ClwPXemWzDQO0TSPe+asNAYac4l+Rfw0Dc660e3mPDQFsM8WHxa8NAbpk5siZyw0Ahw+vHZnHDQPY8dZ9mdcNAL2YEVL51w0B7HcP94nXDQMOY7gXvc8NAM8vRvB95w0AXKHN5annDQP2kU6aXeMNADSH1X/Z3w0DrW/ZMNHTDQFYQGODne8NAH2DnjPiAw0Cqh2AE5ILDQNyI9EW1gMNAnVdVxRF/w0D9TQ8xaH7DQJa9ZqWzfcNA2P2kl4eBw0Amw6ILqILDQOcZe6xfgsNAHn47u7KEw0C/ymCFOYjDQEu7c+LJisNAUM6hQqKMw0DW/nLQUozDQOlLJToWjMNAJoZusxuMw0APZqOEYIvDQGuWkTgBjMNAvbF01TCNw0Db489g/43DQKUTxCOzi8NAosFVW6mIw0AfGbVoRorDQBM6/wZTisNAUM0Bj/6Jw0Ds+DqGEYrDQCaKOcLsicNAVTdvrZaJw0DrHprZdYnDQKSLXW8SicNAHg1s0M2Hw0AeDWzQzYfDQA==\",\"dtype\":\"float64\",\"shape\":[77]},\"x\":{\"__ndarray__\":\"AACMuc2CdkIAAIy5zYJ2QgAAAgbOgnZCAKBRMs6CdkIAEIJmzoJ2QgAApcDOgnZCANARK8+CdkIAoBthz4J2QgBQmpDPgnZCALD5z8+CdkIAEK020IJ2QgAAm6XQgnZCAODWC9GCdkIA0MZh0YJ2QgBgNbbRgnZCAJDRFNKCdkIAwA540oJ2QgBAhOHSgnZCAODPO9OCdkIAADeg04J2QgBwLB/UgnZCAGAoo9SCdkIAMFQZ1YJ2QgDgLHTVgnZCADCf6dWCdkIA8EJ81oJ2QgAgAhXXgnZCAHCNZteCdkIAYHrF14J2QgAQ2Q/YgnZCAFCSOtiCdkIA0AKV2IJ2QgCwYPLYgnZCAPDtCNmCdkIAcMZQ2YJ2QgCgA8PZgnZCABATU9qCdkIAUBu+2oJ2QgDQrEzbgnZCAODTw9uCdkIAQEtD3IJ2QgDApaTcgnZCAFACLN2CdkIAIOiD3YJ2QgDAs+fdgnZCAMBfI96CdkIAAPSa3oJ2QgDg8vvegnZCAHDyVt+CdkIA8Oyq34J2QgDwDgbggnZCAMD6VuCCdkIAgEiz4IJ2QgBA/OjggnZCAKBDD+GCdkIAQLY94YJ2QgBA7l7hgnZCAPC0g+GCdkIAMMGg4YJ2QgAw2cPhgnZCANDS7OGCdkIAwOII4oJ2QgCQCBbignZCACDHNuKCdkIAIEpH4oJ2QgDQPGzignZCAHDYhOKCdkIAIE2f4oJ2QgDgOq3ignZCAJDRx+KCdkIAMALP4oJ2QgBAytzignZCACBh6OKCdkIA8ML14oJ2QgCgfwbjgnZCAFCkDOOCdkIAUKQM44J2Qg==\",\"dtype\":\"float64\",\"shape\":[77]},\"y1\":{\"__ndarray__\":\"AAAAAAAA8D8AAAAAAADwP9cLhcYZ9u8/MP+y67b07z+vPjK9AvPvP4G1WhqM7+8/tV00ljzX7z+4brmB8cnvPxOqz81Fye8/J82f6FXT7z9gHsWhX83vP8g3OvwE0u8/yCfhG7LI7z+bUSaJHLnvP75Lg6Rvve8/Hov8s1bI7z9525eM98fvP8LeW1/Nvu8/03LsgUm67z+GXfx+zLDvP23a8oiPsO8/9adMksio7z/hn/Wgka7vPykqMw8KuO8/clvj1Ym37z/JchM6lsTvP+4wxrU0yO8/1nenLC3F7z9bpwoNHNPvP6I5c/cR0O8/x+1p4Em+7z8qqhD/zMTvP8mA5/8H0u8/6KJY7jPc7z9YjkF/+drvP4HtsPWG4e8/1tL2pxbi7z/AmJG5UuLvP4AUwZMf3+8/M+H3iqDn7z9cq979GujvP+nrlJPB5u8/uJL+V7nl7z8f8dMUkd/vP2XxNE8v7O8/hgUjyHv07z8LTDUAoffvP2PNDo4N9O8/+Hb8PV7x7z+5MFFnSPDvP3xbB5kg7+8/ZxNIJGb17z+G4Ua+PvfvPx/hYivI9u8/q6WkHJf67z+rnAcfLwDwP9h3ctBIAvA/9erPyMsD8D9E1cWzigPwPxxuuxFZA/A/zGmqjV0D8D80D5c2xALwP+rLa9xHA/A/EwymlEAE8D9q9CPI6QTwP0MGmOUHA/A/ZL+wvIoA8D+W0AUc3QHwPxWjRnLnAfA/BUPnP6IB8D9KZE3JsQHwP3TB/KqTAfA/dd1yJk0B8D/EeAdCMgHwPyoCMtHgAPA/gECHxq3/7z+AQIfGrf/vPw==\",\"dtype\":\"float64\",\"shape\":[77]},\"y2\":{\"__ndarray__\":\"AAAAAAAAAAAAAAAAAAAAACAAO6Bz776/AK+FHA1Zkb+Aq8rLylOVvwAEv7RGrqW/aCkBH+gH078gIrRa59/EvwBIO00V4YC/wD9NSniovz/gR+kqw7uyvwDGbMmuN60/oCVIVxdNvb+QpczyE4TIv4A7BS3RQ6s/AKMF+MEswT8ABpfjPbZyv2A/Bf5L1ry/QPPpwxxyrL9gIxWSz+e9vwC4eBufC2i/wPgcaa+KuL+ARIETHEayP0C1AMZp5L0/AJQfqwJEeb9g3FLe8JHEPwC3e7HSyKY/QFUCMFYQo78gEXejje3FP0B2FoTSGaO/EJCqDYDyy7+AzTJr4IO0P6CViQG30sQ/APdMfzT3vz8AOrx4WdeOv0Ag7/PekbQ/AAi0H6UrfD8AUHbe44xnP4BW+JhJEqS/ACOcGG6uuj8AgBIqtvx3P4A+0hJS6pC/AJ1W7Dziib8g/eqfq02zv6DR+R5Ly8M/wHHR5BL/uT+ANU4vtK+jP4B7j7RjX6a/AGJLkvrNoL8A9ABsZC6LvwByhGdc8Yy/wAElHa6jsz8AkI6HLBuXPwBKb00IL3e/gLGAIEHUpz+A70JbVhGyP4AdQmbcQKo/AJhdUW7ioj8ABuNHMWZ5vwCQwVICX3O/AMApn7kAPD8AUaRstuyNvwAkEzPysYk/ACD3vgNFmD8ARrRCpIGQP8ACClxYgKe/wLLEtZsWr78ADJJoGIWgPwAw1uDjJFA/AN7CKHYEe78AACI9NURYPwAQxVIxhWe/AGCeKg+Je78ADLOUvgBlvwCYHKGyzX+/gF2+dM/2mb8AAAAAAAAAAA==\",\"dtype\":\"float64\",\"shape\":[77]},\"y3\":{\"__ndarray__\":\"AAAAAAAAAAAAAAAAAAAAACAAO6Bz776/AK+FHA1Zkb+Aq8rLylOVvwAEv7RGrqW/aCkBH+gH078gIrRa59/EvwBIO00V4YC/AAAAAAAAAADgR+kqw7uyvwAAAAAAAAAAoCVIVxdNvb+QpczyE4TIvwAAAAAAAAAAAAAAAAAAAAAABpfjPbZyv2A/Bf5L1ry/QPPpwxxyrL9gIxWSz+e9vwC4eBufC2i/wPgcaa+KuL8AAAAAAAAAAAAAAAAAAAAAAJQfqwJEeb8AAAAAAAAAAAAAAAAAAAAAQFUCMFYQo78AAAAAAAAAAEB2FoTSGaO/EJCqDYDyy78AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOrx4WdeOvwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIBW+JhJEqS/AAAAAAAAAAAAAAAAAAAAAIA+0hJS6pC/AJ1W7Dziib8g/eqfq02zvwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIB7j7RjX6a/AGJLkvrNoL8A9ABsZC6LvwByhGdc8Yy/AAAAAAAAAAAAAAAAAAAAAABKb00IL3e/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABuNHMWZ5vwCQwVICX3O/AAAAAAAAAAAAUaRstuyNvwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMACClxYgKe/wLLEtZsWr78AAAAAAAAAAAAAAAAAAAAAAN7CKHYEe78AAAAAAAAAAAAQxVIxhWe/AGCeKg+Je78ADLOUvgBlvwCYHKGyzX+/gF2+dM/2mb8AAAAAAAAAAA==\",\"dtype\":\"float64\",\"shape\":[77]}},\"selected\":{\"id\":\"a276e4bb-c206-4e6a-adb5-bc34e3ece458\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"aac8b388-997a-4810-9572-5887f8ff58fa\",\"type\":\"UnionRenderers\"}},\"id\":\"7de786de-a75b-46ac-895c-4e01384535f1\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"dimension\":1,\"grid_line_alpha\":{\"value\":0.7},\"grid_line_color\":{\"value\":\"#E4E4E4\"},\"plot\":{\"id\":\"dd7a8270-8d27-488b-888a-0368fe1cefd9\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"afa0f998-d9aa-4ea8-b62d-98ae01f70a67\",\"type\":\"BasicTicker\"}},\"id\":\"54ec5e5a-516b-47ae-a7df-71c53f212f41\",\"type\":\"Grid\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"7dbf681d-837f-4fab-9a5c-71cdf400f975\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"ceba60db-b174-45a9-ba43-f07b3543333f\",\"type\":\"HelpTool\"},{\"attributes\":{\"axis_label\":\"Datetime\",\"axis_label_text_font\":\"arial\",\"axis_label_text_font_style\":null,\"formatter\":{\"id\":\"887a8840-67aa-4048-81b7-7e978283503e\",\"type\":\"DatetimeTickFormatter\"},\"major_label_text_font_size\":{\"value\":\"9.5pt\"},\"plot\":{\"id\":\"8501c36f-a941-497a-a849-1c9529a4d78e\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"08dd9bfd-02c8-4aff-aded-08210f7fed5f\",\"type\":\"DatetimeTicker\"}},\"id\":\"da572bf5-c9b5-45aa-8492-f63260815349\",\"type\":\"DatetimeAxis\"},{\"attributes\":{},\"id\":\"e2543d03-5a57-4e90-88cf-47443be19e86\",\"type\":\"YearsTicker\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"b4c31fcd-2c5e-40b3-8fb7-9057585cf5e0\",\"type\":\"DaysTicker\"},{\"attributes\":{\"dimension\":1,\"grid_line_alpha\":{\"value\":0.7},\"grid_line_color\":{\"value\":\"#E4E4E4\"},\"plot\":{\"id\":\"f2e5768c-11db-43a5-bb6c-632e72c20580\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"4f0f436f-65c1-413e-9490-883b7f81cb27\",\"type\":\"BasicTicker\"}},\"id\":\"ab516b74-eebc-4506-a92c-2b7e9d73f5ea\",\"type\":\"Grid\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"94259468-7c72-441e-ba2c-b6859b6b3455\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{},\"id\":\"c53520d0-9b73-4a89-a47a-08aa433d499b\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"4f0f436f-65c1-413e-9490-883b7f81cb27\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"f601498a-5ffd-4f3a-a187-ec8b542cc655\",\"type\":\"YearsTicker\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"537ce53b-7666-4b03-89a1-f8ae2f2fcb49\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"fccb5b3f-2cc8-4cd2-a5b0-a89c85f3bbe5\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"value\":4.25},\"top\":{\"field\":\"top\"},\"width\":{\"value\":4.25},\"x\":{\"field\":\"x\"}},\"id\":\"3058d640-f699-4177-b2e6-dbda76bbabfa\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1a965594-abed-4129-a401-596e3beea989\",\"type\":\"LinearScale\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"94259468-7c72-441e-ba2c-b6859b6b3455\",\"type\":\"AdaptiveTicker\"},{\"id\":\"a080e495-1132-47d3-9d74-e1809018c548\",\"type\":\"AdaptiveTicker\"},{\"id\":\"0e65af9b-469f-4329-90ea-c5cbb6e6651f\",\"type\":\"AdaptiveTicker\"},{\"id\":\"e8cfbb0c-f03d-4c86-8644-c417f60f79a3\",\"type\":\"DaysTicker\"},{\"id\":\"977e42b4-f076-4647-bbdd-159ea5ed8018\",\"type\":\"DaysTicker\"},{\"id\":\"f2edf1da-9d45-45ff-a878-a51e23e48f80\",\"type\":\"DaysTicker\"},{\"id\":\"69acbfb2-bf0f-49a6-a016-a15ae64c441d\",\"type\":\"DaysTicker\"},{\"id\":\"ab3531d4-82d3-4999-b724-5a80d99de1a6\",\"type\":\"MonthsTicker\"},{\"id\":\"537ce53b-7666-4b03-89a1-f8ae2f2fcb49\",\"type\":\"MonthsTicker\"},{\"id\":\"02cc74a2-3455-4fb0-9709-e27aa1057258\",\"type\":\"MonthsTicker\"},{\"id\":\"88ebac88-e17a-4308-86dd-80d94939c3d7\",\"type\":\"MonthsTicker\"},{\"id\":\"f601498a-5ffd-4f3a-a187-ec8b542cc655\",\"type\":\"YearsTicker\"}]},\"id\":\"08dd9bfd-02c8-4aff-aded-08210f7fed5f\",\"type\":\"DatetimeTicker\"},{\"attributes\":{\"callback\":null,\"mode\":\"vline\",\"renderers\":[{\"id\":\"d9459542-6484-4985-8f72-e70437c4ff05\",\"type\":\"GlyphRenderer\"}],\"tooltips\":[[\"Cash\",\"$@money{0.000 a}\"]]},\"id\":\"d0db49b5-d329-4534-bbfd-1589743eb3e6\",\"type\":\"HoverTool\"},{\"attributes\":{\"source\":{\"id\":\"7de786de-a75b-46ac-895c-4e01384535f1\",\"type\":\"ColumnDataSource\"}},\"id\":\"85210663-fdbe-437e-b197-08f8a1467581\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"6db156a9-df85-4b93-a5be-2f08a6a2e8ec\",\"type\":\"PanTool\"},{\"attributes\":{\"line_color\":\"green\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y1\"}},\"id\":\"ce1bd57d-9aef-4b66-86ea-36f5e32bd5da\",\"type\":\"Line\"},{\"attributes\":{\"fill_alpha\":0.1,\"fill_color\":\"#1f77b4\",\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y3\"}},\"id\":\"a386cf44-9e2a-4344-856e-40a436af168c\",\"type\":\"Patch\"},{\"attributes\":{},\"id\":\"dbfdc5d9-e82b-4855-99fa-320de5b25c70\",\"type\":\"HelpTool\"},{\"attributes\":{\"children\":[{\"id\":\"dd7a8270-8d27-488b-888a-0368fe1cefd9\",\"subtype\":\"Figure\",\"type\":\"Plot\"}]},\"id\":\"d68e4e2b-f4ce-4315-93d5-fccc05e0d01c\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"77c3543c-8a28-452f-a8a0-f24f20f0ffe7\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"977e42b4-f076-4647-bbdd-159ea5ed8018\",\"type\":\"DaysTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"4ef4acf9-bbee-45ce-ae11-8080a7896737\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"2764a2c7-6f26-4506-99a5-034e24f1c194\",\"type\":\"PanTool\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"2fea732b-dd74-442e-853b-54571dfa72a2\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"a080e495-1132-47d3-9d74-e1809018c548\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"source\":{\"id\":\"7de786de-a75b-46ac-895c-4e01384535f1\",\"type\":\"ColumnDataSource\"}},\"id\":\"d4479b5e-1208-4801-8fac-b336353def5b\",\"type\":\"CDSView\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"b95a2747-4d25-4835-bad9-7a6d778f3147\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"9bfb9edd-0c00-4929-8c6e-5a7de7207568\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis_label_text_font\":\"arial\",\"axis_label_text_font_style\":null,\"formatter\":{\"id\":\"b03c1faf-7697-43fc-9321-493180e49753\",\"type\":\"DatetimeTickFormatter\"},\"major_label_text_font_size\":{\"value\":\"9.5pt\"},\"plot\":{\"id\":\"dd7a8270-8d27-488b-888a-0368fe1cefd9\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"45faab98-1289-4aef-985f-6bb9329c9b34\",\"type\":\"DatetimeTicker\"}},\"id\":\"cadbf11d-72b5-488c-97a1-58d7712d42a9\",\"type\":\"DatetimeAxis\"},{\"attributes\":{\"line_alpha\":0,\"line_color\":\"#1f77b4\",\"line_width\":0,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y2\"}},\"id\":\"61be5d8d-8bbf-4e45-8ba4-dddd60c7de03\",\"type\":\"Line\"},{\"attributes\":{\"callback\":null,\"data\":{\"top\":{\"__ndarray__\":\"wD9NSniovz8AxmzJrjetP4A7BS3RQ6s/AKMF+MEswT+ARIETHEayP0C1AMZp5L0/YNxS3vCRxD8At3ux0simPyARd6ON7cU/gM0ya+CDtD+glYkBt9LEPwD3TH80978/QCDv896RtD8ACLQfpSt8PwBQdt7jjGc/ACOcGG6uuj8AgBIqtvx3P6DR+R5Ly8M/wHHR5BL/uT+ANU4vtK+jP8ABJR2uo7M/AJCOhywblz+AsYAgQdSnP4DvQltWEbI/gB1CZtxAqj8AmF1RbuKiPwDAKZ+5ADw/ACQTM/KxiT8AIPe+A0WYPwBGtEKkgZA/AAySaBiFoD8AMNbg4yRQPwAAIj01RFg/\",\"dtype\":\"float64\",\"shape\":[33]},\"x\":{\"__ndarray__\":\"ALD5z8+CdkIAAJul0IJ2QgBgNbbRgnZCAJDRFNKCdkIAMFQZ1YJ2QgDgLHTVgnZCAPBCfNaCdkIAIAIV14J2QgBgesXXgnZCANACldiCdkIAsGDy2IJ2QgDw7QjZgnZCAKADw9mCdkIAEBNT2oJ2QgBQG77agnZCAODTw9uCdkIAQEtD3IJ2QgDAs+fdgnZCAMBfI96CdkIAAPSa3oJ2QgDA+lbggnZCAIBIs+CCdkIAoEMP4YJ2QgBAtj3hgnZCAEDuXuGCdkIA8LSD4YJ2QgDQ0uzhgnZCAJAIFuKCdkIAIMc24oJ2QgAgSkfignZCACBNn+KCdkIA4Dqt4oJ2QgAwAs/ignZC\",\"dtype\":\"float64\",\"shape\":[33]}},\"selected\":{\"id\":\"01d4448f-5a4f-4c8c-9ccf-83b6febbe13d\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"0e3b4c67-a6dd-4272-8881-95fe2ee5649e\",\"type\":\"UnionRenderers\"}},\"id\":\"97119daa-9012-41a5-a2a5-16afde415412\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"e2e34abc-d439-41df-ab0e-0ef480cb9296\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"data_source\":{\"id\":\"7de786de-a75b-46ac-895c-4e01384535f1\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"ce1bd57d-9aef-4b66-86ea-36f5e32bd5da\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"5344c29f-72eb-4316-bb83-b0f5758d5606\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"6a584da6-84d0-43a4-81c3-3f06327f11fd\",\"type\":\"CDSView\"}},\"id\":\"d9459542-6484-4985-8f72-e70437c4ff05\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"d44e44b1-d994-4f67-9b85-5e7872148ff7\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_color\":{\"value\":\"#29399F\"},\"line_alpha\":{\"value\":0.9},\"line_color\":{\"value\":\"#29399F\"},\"line_width\":{\"value\":4.25},\"top\":{\"field\":\"top\"},\"width\":{\"value\":4.25},\"x\":{\"field\":\"x\"}},\"id\":\"bd0a8658-73dd-439b-b9d3-ae2545d26074\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"66e583e2-e6e5-4c40-b8b6-89462e19fc4e\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"6db156a9-df85-4b93-a5be-2f08a6a2e8ec\",\"type\":\"PanTool\"},{\"id\":\"b26ecd07-c886-4ae6-9e31-bb8c52070a00\",\"type\":\"WheelZoomTool\"},{\"id\":\"b23ae5a1-2b88-4069-b402-c112ca95b910\",\"type\":\"BoxZoomTool\"},{\"id\":\"464ab49c-c50c-4770-88b5-b9990bcc1060\",\"type\":\"SaveTool\"},{\"id\":\"605139a5-88df-4fd7-8218-17f56b15b63f\",\"type\":\"ResetTool\"},{\"id\":\"ceba60db-b174-45a9-ba43-f07b3543333f\",\"type\":\"HelpTool\"},{\"id\":\"b68874eb-6fc9-47c6-abce-3ed7befdf925\",\"type\":\"HoverTool\"}]},\"id\":\"22b86716-c471-4abc-8c3a-64ec946843a7\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"d4251c26-d979-45ef-9748-9f3c5c376208\",\"type\":\"YearsTicker\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"0e65af9b-469f-4329-90ea-c5cbb6e6651f\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":0,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y2\"}},\"id\":\"9d3dc3f0-8306-4cb9-a993-3ae8080c69e9\",\"type\":\"Line\"},{\"attributes\":{\"items\":[{\"id\":\"48d74371-d03f-425e-a7f6-f988399fbdae\",\"type\":\"LegendItem\"}],\"location\":\"bottom_left\",\"plot\":{\"id\":\"f2e5768c-11db-43a5-bb6c-632e72c20580\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"ac696a48-71bd-4747-85ca-fabc63ffd881\",\"type\":\"Legend\"},{\"attributes\":{\"axis_label\":\"Cumulative Returns\",\"axis_label_text_font\":\"arial\",\"axis_label_text_font_style\":null,\"formatter\":{\"id\":\"77c3543c-8a28-452f-a8a0-f24f20f0ffe7\",\"type\":\"BasicTickFormatter\"},\"major_label_text_font_size\":{\"value\":\"9.5pt\"},\"plot\":{\"id\":\"f2e5768c-11db-43a5-bb6c-632e72c20580\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"4f0f436f-65c1-413e-9490-883b7f81cb27\",\"type\":\"BasicTicker\"}},\"id\":\"643e9c79-d1eb-47db-bc17-2fba2d3b7b18\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"22b9b048-b8dd-40bc-bad2-eed54a8e46d3\",\"type\":\"LinearScale\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"e8cfbb0c-f03d-4c86-8644-c417f60f79a3\",\"type\":\"DaysTicker\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"5d05a9d5-6ada-4e51-a707-88347195bea3\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"background_fill_color\":{\"value\":null},\"below\":[{\"id\":\"cadbf11d-72b5-488c-97a1-58d7712d42a9\",\"type\":\"DatetimeAxis\"}],\"left\":[{\"id\":\"b64e5a90-4df6-467c-a4c1-635cedc5c283\",\"type\":\"LinearAxis\"}],\"plot_height\":300,\"plot_width\":800,\"renderers\":[{\"id\":\"cadbf11d-72b5-488c-97a1-58d7712d42a9\",\"type\":\"DatetimeAxis\"},{\"id\":\"db6367df-3294-4540-bd99-c6831bd4968e\",\"type\":\"Grid\"},{\"id\":\"b64e5a90-4df6-467c-a4c1-635cedc5c283\",\"type\":\"LinearAxis\"},{\"id\":\"54ec5e5a-516b-47ae-a7df-71c53f212f41\",\"type\":\"Grid\"},{\"id\":\"b95a2747-4d25-4835-bad9-7a6d778f3147\",\"type\":\"BoxAnnotation\"},{\"id\":\"ef70dcde-0a44-454d-9952-654055f33bd3\",\"type\":\"GlyphRenderer\"},{\"id\":\"61efa8d1-66c7-43e7-9b8e-d428d129b185\",\"type\":\"GlyphRenderer\"},{\"id\":\"fe235ab0-e136-4435-9abe-99ab3e6d50a4\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"90475ce0-8113-45f5-b94f-9c067e07e9b9\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"22b86716-c471-4abc-8c3a-64ec946843a7\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"fe79392f-8f3d-499e-b862-afa5a4d8579c\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"8e780530-8f69-443c-951d-158d7e1b774f\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"df5c8ee3-ddc1-49df-b214-2fb828974a51\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1a965594-abed-4129-a401-596e3beea989\",\"type\":\"LinearScale\"}},\"id\":\"dd7a8270-8d27-488b-888a-0368fe1cefd9\",\"subtype\":\"Figure\",\"type\":\"Plot\"}],\"root_ids\":[\"47a37777-e138-4995-9abf-89e8b816c1f5\"]},\"title\":\"Bokeh Application\",\"version\":\"0.13.0\"}};\n",
       "  var render_items = [{\"docid\":\"5621c795-c739-4257-86c6-702b53bc9656\",\"roots\":{\"47a37777-e138-4995-9abf-89e8b816c1f5\":\"3a50e5a4-990d-4033-aff2-0d2ae9d3c5e6\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "47a37777-e138-4995-9abf-89e8b816c1f5"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "backtest_req.simulate_trading()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
